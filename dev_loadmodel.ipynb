{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minus-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from anytree import Node, RenderTree, find, Walker,DoubleStyle,LevelOrderIter,findall\n",
    "\n",
    "class ConfussionMatrix:\n",
    "    def __init__(self,tp=0,fp=0,fn=0,tn=0,support=0,label=None):\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        self.tn = tn\n",
    "        self.support = support\n",
    "        self.label=label\n",
    "        \n",
    "    def get_p(self):\n",
    "        self.p = self.tp + self.fn\n",
    "        return self.p\n",
    "    \n",
    "    def get_n(self):\n",
    "        self.n = self.fp + self.tn\n",
    "        return self.n\n",
    "    \n",
    "    def accuracy(self):\n",
    "        p = self.get_p()\n",
    "        n = self.get_n()\n",
    "        if p == 0.0 or n == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.tp+self.tn)/(p+n)\n",
    "    \n",
    "    def error_rate(self):\n",
    "        p = self.get_p()\n",
    "        n = self.get_n()\n",
    "        if p == 0.0 or n == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.fp+self.fn)/(p+n)\n",
    "    \n",
    "    def recall(self):\n",
    "        p = self.get_p()\n",
    "        if p == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.tp)/(p)\n",
    "    \n",
    "    def specificity(self):\n",
    "        n = self.get_n()\n",
    "        if n == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.tn)/(n)\n",
    "    \n",
    "    def percision(self):\n",
    "        divider = self.tp + self.fp\n",
    "        if(divider == 0.0):\n",
    "            return 0.0\n",
    "        return float(self.tp)/(divider)\n",
    "    \n",
    "    def f1(self):\n",
    "        percision = self.percision()\n",
    "        recall = self.recall()\n",
    "        total = percision + recall\n",
    "        if(total == 0.0):\n",
    "            return 0.0\n",
    "        return float(2*percision*recall)/(percision+recall)\n",
    "    \n",
    "    def weighted_f1(self):\n",
    "        return float(self.f1()) * self.support\n",
    "    \n",
    "    def weighted_recall(self):\n",
    "        return float(self.recall()) * self.support\n",
    "    \n",
    "    def weighted_percision(self):\n",
    "        return float(self.percision()) * self.support\n",
    "    \n",
    "    def weighted_error(self):\n",
    "        return float(self.error_rate()) * self.support \n",
    "    \n",
    "    def display_report(self,name):\n",
    "#         print('%5s %5s %5s %5s %5s' % ('Name','Accuracy','Percision','Recall','F1'))\n",
    "        print('%7s'% name,end =' ')\n",
    "        print('%7.2f' % self.accuracy(),end=' ')\n",
    "        print('%7.2f' %self.percision(),end=' ')\n",
    "        print('%7.2f' %self.recall(),end=' ')\n",
    "        print('%7.2f' %self.f1(),end=' ')\n",
    "        print('%7d' %self.support)\n",
    "    def display_matrix(self):\n",
    "        print(f'TP = {self.tp} FP = {self.fp}')\n",
    "        print(f'FN = {self.fn} TN = {self.tn}')\n",
    "\n",
    "class Report:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def create_cm_list(self,actualList,predictionList,labels):\n",
    "        cm_list = {}\n",
    "        for label in labels:\n",
    "            TP = 0\n",
    "            FN = 0\n",
    "            FP = 0\n",
    "            TN = 0\n",
    "            mask = np.isin(actualList,label)\n",
    "            support = mask.sum()\n",
    "            for index,predict in enumerate(predictionList):\n",
    "                actual = actualList[index]\n",
    "                if(predict == label == actual):\n",
    "                    TP +=1\n",
    "                elif(predict == actual and predict != label):\n",
    "                    TN +=1\n",
    "                elif(predict != actual and predict == label):\n",
    "        #             FN +=1\n",
    "                    FP += 1\n",
    "                elif(predict != actual and actual != label):\n",
    "                    TN +=1\n",
    "                elif(predict != actual and actual == label):\n",
    "        #             FP +=1\n",
    "                    FN+=1\n",
    "            cm = ConfussionMatrix(TP,FP,FN,TN,support,label)\n",
    "            cm_list[label] = cm\n",
    "        return cm_list\n",
    "\n",
    "    def create_report(self,cm_list,labels):\n",
    "        totalTP =0\n",
    "        totalFP =0\n",
    "        totalFN =0\n",
    "        totalSupport =0\n",
    "        totalF1 =0\n",
    "        totalRecall =0\n",
    "        totalPercision =0\n",
    "        totalWeightedRecall =0\n",
    "        totalWeightedPercision =0\n",
    "        totalWeightedF1=0\n",
    "        totalError=0\n",
    "        totalWeightedError=0\n",
    "        for label in labels:\n",
    "            cm = cm_list[label]\n",
    "            totalTP += cm.tp\n",
    "            totalFP += cm.fp\n",
    "            totalFN += cm.fn\n",
    "            totalF1 += cm.f1()\n",
    "            totalWeightedF1 += cm.weighted_f1()\n",
    "            totalSupport += cm.support\n",
    "            totalRecall += cm.recall()\n",
    "            totalPercision += cm.percision()\n",
    "            totalWeightedRecall += cm.weighted_recall()\n",
    "            totalWeightedPercision += cm.weighted_percision()\n",
    "            totalError += cm.error_rate()\n",
    "            totalWeightedError += cm.weighted_error()\n",
    "            print('-----------------------------')\n",
    "            print(f'Label:{cm.label}')\n",
    "            print(f'Accuracy: {cm.accuracy():.2f}')\n",
    "            print(f'Error: {cm.error_rate():.2f}')\n",
    "            print(f'Specificity: {cm.specificity():.2f}')\n",
    "            print(f'Percision: {cm.percision():.2f}')\n",
    "            print(f'Recall: {cm.recall():.2f}')\n",
    "            print(f'F1-score: {cm.f1():.2f}')\n",
    "            print(f'support: {cm.support:d}')\n",
    "            cm.display_matrix()\n",
    "            \n",
    "        print('-----------------------------')\n",
    "        nol = len(labels)\n",
    "        P = totalTP+totalFN\n",
    "        micro_f1 = totalTP/P\n",
    "        macro_f1 = (totalF1)/nol\n",
    "        weigthed_f1 = totalWeightedF1 / totalSupport\n",
    "        # if(nol > 2):\n",
    "        print(f'Micro f1/Accuracy: {micro_f1:.2f}')\n",
    "        print(f'Macro f1: {macro_f1:.2f}')\n",
    "        print(f'Weighted f1: {weigthed_f1:.2f}')\n",
    "        \n",
    "        micro_error = (totalFP+totalFN)/totalSupport\n",
    "        macro_error = (totalError)/nol\n",
    "        weigthed_error = totalWeightedError / totalSupport\n",
    "        # if(nol > 2):\n",
    "        print(f'Micro error: {micro_error:.2f}')\n",
    "        print(f'Macro error: {macro_error:.2f}')\n",
    "        print(f'Weighted error: {weigthed_error:.2f}')     \n",
    "        \n",
    "        micro_percision = (totalTP)/(totalTP+totalFP)\n",
    "        macro_percision = totalPercision / nol\n",
    "        weighted_percision = totalWeightedPercision / totalSupport\n",
    "        # if(nol > 2):\n",
    "        print(f'Micro percision: {micro_percision:.2f}')\n",
    "        print(f'Macro percision: {macro_percision:.2f}')\n",
    "        print(f'Weighted percision: {weighted_percision:.2f}')\n",
    "\n",
    "        micro_recall = totalTP/P\n",
    "        macro_recall = totalRecall / nol\n",
    "        weighted_recall = totalWeightedRecall / totalSupport\n",
    "        # if(nol > 2):\n",
    "        print(f'Micro recall: {micro_recall:.2f}')\n",
    "        print(f'Macro recall: {macro_recall:.2f}')\n",
    "        print(f'Weighted recall: {weighted_recall:.2f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "friendly-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ConfussionMatrix import Report,ConfussionMatrix\n",
    "from collections import defaultdict\n",
    "\n",
    "class Feature:\n",
    "    def __init__(self, name=None, unique=None,info=0.0,\n",
    "                 df=None,gain=0.0,split_info=0.0):\n",
    "        \n",
    "        self.name = name\n",
    "        self.unique = unique\n",
    "        self.info = info\n",
    "        self.gain = gain\n",
    "        self.split_info = split_info\n",
    "        self.gain_ratio = 0.0\n",
    "        self.dataset = df\n",
    "\n",
    "class Prior:\n",
    "    def __init__(self, feature=None, label=None,feature_support=0,label_support=0,label_count=0):\n",
    "        self.feature = feature\n",
    "        self.label = label\n",
    "        self.feature_support = feature_support\n",
    "        self.label_support = label_support\n",
    "        self.label_count = label_count\n",
    "    \n",
    "    def probability(self):\n",
    "        feature_support = self.feature_support\n",
    "        label_support = self.label_support\n",
    "        if (label_support == 0):\n",
    "            return 0\n",
    "        elif(feature_support == 0):\n",
    "            feature_support += 1\n",
    "            label_support += self.label_count\n",
    "        return feature_support/label_support\n",
    "            \n",
    "class NaiveBayesian:\n",
    "    def __init__(self,verbose=True):\n",
    "        self.except_features = []\n",
    "        self.feature_list={}\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def read_csv(self,filename):\n",
    "        df = pd.read_table(filename, sep=';', engine='python')\n",
    "        self.label_name = df.columns[-1]\n",
    "        self.number_of_entries = len(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def remove_feature(self,feature):\n",
    "        if feature not in self.except_features:\n",
    "            self.except_features.append(feature)\n",
    "            self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "#             self.df = self.df.drop(feature,axis=1)\n",
    "        else:\n",
    "            print(f'{feature} is removed!')\n",
    "            \n",
    "    def find_feature(self,dataset):\n",
    "        feature_list = {}\n",
    "        for col in dataset:\n",
    "            if col not in self.except_features:\n",
    "                feature = Feature(name=col,unique=dataset[col].unique())\n",
    "                feature_list[col] = feature\n",
    "        return feature_list\n",
    "    \n",
    "    def create_model(self):\n",
    "        feature_list = self.find_feature(self.df)\n",
    "        key_list = list(feature_list)\n",
    "        label_dict = {}\n",
    "        labelObj = feature_list[self.label_name]\n",
    "        for label in labelObj.unique:\n",
    "            label_idxs = self.df[(self.df[labelObj.name]==label)].index\n",
    "            label_dict[label] = len(label_idxs)\n",
    "\n",
    "        prior_dict = {}\n",
    "        labelObj = feature_list[self.label_name]  \n",
    "        for key in feature_list:\n",
    "            featureObj = feature_list[key]\n",
    "            value_dict={}\n",
    "            for unique in featureObj.unique: \n",
    "                unique_list={}\n",
    "                for label in labelObj.unique:\n",
    "                    feature_idxs = self.df[((self.df[featureObj.name]==unique)&(self.df[labelObj.name]==label))].index\n",
    "                    feature_count = len(feature_idxs)\n",
    "                    label_count = label_dict[label]\n",
    "                    prior = Prior(unique, label,feature_count,label_count,len(labelObj.unique))\n",
    "                    unique_list[label] = prior\n",
    "                value_dict[unique] = unique_list\n",
    "            prior_dict[key] = value_dict\n",
    "        self.prior_dict = prior_dict\n",
    "        self.label_dict = label_dict\n",
    "        self._feature_list = feature_list\n",
    "        \n",
    "    def get_model(self):\n",
    "        data = []\n",
    "        for key in self.prior_dict:\n",
    "            value_dict = self.prior_dict[key]\n",
    "            for value_key in value_dict:\n",
    "                label_dict = value_dict[value_key]\n",
    "                for label_key in label_dict:\n",
    "                    prior = label_dict[label_key]\n",
    "                    ls = {'feature':key,\n",
    "                          'X':prior.feature,\n",
    "                          'C':prior.label,\n",
    "                          'Xi':prior.feature_support,\n",
    "                          'Ci':prior.label_support,\n",
    "                          'LabelCount':prior.label_count,\n",
    "                          'Probability':prior.probability()\n",
    "                         }\n",
    "                    data.append(ls)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    def save(self,file):\n",
    "        df = self.get_model()\n",
    "        df.to_csv(file)\n",
    "        \n",
    "    def read_testset(self,file):\n",
    "        df = pd.read_table(file, sep=';', engine='python')\n",
    "        label_name = df.columns[-1]\n",
    "        number_of_entries = len(df)\n",
    "        features = [item for item in df.columns if item != label_name]\n",
    "        return label_name,number_of_entries,df,features        \n",
    "        \n",
    "    def predict(self,data):\n",
    "        if self.verbose:\n",
    "            print('-----------------------Predict for-----------------------')\n",
    "            print(data)\n",
    "            print()\n",
    "        key_list = list(self.prior_dict)\n",
    "        label_result = {}\n",
    "        for label_key in self.label_dict:\n",
    "            pX = 1.0\n",
    "            if self.verbose:\n",
    "                print(f'Label: {label_key}')\n",
    "            for class_key in key_list:\n",
    "                feature = data[class_key]\n",
    "                try:\n",
    "                    feature_dict = self.prior_dict[class_key][feature][label_key]\n",
    "                    if self.verbose:\n",
    "                        print(feature,feature_dict.probability())\n",
    "                    pX *= feature_dict.probability()\n",
    "                except:\n",
    "                    print(f'Missing data for {class_key} {feature}')\n",
    "            try:\n",
    "                pC = float(pX) * (self.label_dict[label_key]/self.number_of_entries)\n",
    "            except:\n",
    "                pC = 0.0\n",
    "            label_result[label_key] = pC\n",
    "            if self.verbose:\n",
    "                print(f\"P({label_key}|X): {pC} / P(X)\")\n",
    "                print()\n",
    "\n",
    "            bestPc = 0.0\n",
    "            bestKey = list(label_result)[0]\n",
    "            for label_key in label_result:\n",
    "                if(label_result[label_key] > bestPc):\n",
    "                    bestPc = label_result[label_key]\n",
    "                    bestKey = label_key\n",
    "        if self.verbose:\n",
    "            print(f'Selected label: {bestKey}')\n",
    "            print('-----------------------End predict-----------------------')\n",
    "        return bestKey\n",
    "        \n",
    "    def predict_file(self,file,verbose=None):\n",
    "        label_name,number_of_entries,dataset,features = self.read_testset(file)\n",
    "        predictions = []\n",
    "        if verbose == None:\n",
    "            verbose =self.verbose\n",
    "        if verbose:\n",
    "            print(f'Number of entries: {number_of_entries}')\n",
    "            print(f'Label: {label_name}')\n",
    "            print(f'Features: {features}')\n",
    "        for index in dataset.index:\n",
    "            data = dataset.loc[index]\n",
    "            label = self.predict(data)\n",
    "            predictions.append(label)\n",
    "        return predictions,dataset\n",
    "    \n",
    "    def display_predictions(self,predictions,dataset):\n",
    "#         print(dataset.columns[0],self.label_name,'Predictions')\n",
    "        df = pd.DataFrame(columns=[dataset.columns[0],self.label_name,'Predictions'])\n",
    "        df['Predictions'] = predictions\n",
    "        df[dataset.columns[0]]=dataset[dataset.columns[0]]\n",
    "        df[self.label_name]=dataset[self.label_name]\n",
    "        print(df)\n",
    "        \n",
    "    def multi_level_dict(self):\n",
    "        return defaultdict(self.multi_level_dict)\n",
    "        \n",
    "    def load(self,file):\n",
    "        df = pd.read_csv(file)\n",
    "        data = []\n",
    "        model_list = self.multi_level_dict()\n",
    "        for index in df.index:\n",
    "            feature_class= df['feature'][index]\n",
    "            feature_value = df['X'][index]\n",
    "            label = df['C'][index]\n",
    "            feature_suppot_count = df['Xi'][index]\n",
    "            label_support_count = df['Ci'][index]\n",
    "            label_count = df['LabelCount'][index]\n",
    "            prior = Prior(feature_class, label,feature_suppot_count,label_support_count,label_count)\n",
    "            model_list[feature_class][feature_value][label] = prior\n",
    "        self.prior_dict = model_list\n",
    "        \n",
    "        label_dict = {}\n",
    "        for item in df['C'].unique():\n",
    "            label_dict[item] = 0  \n",
    "        self.label_dict = label_dict\n",
    "        return df\n",
    "    \n",
    "    def info(self):\n",
    "        self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "        print(f'Remove feature: {self.except_features}')\n",
    "        print(f'Available feature: {self.features}')\n",
    "        print(f'Number of entries: {self.number_of_entries}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mounted-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove feature: ['NO']\n",
      "Available feature: ['Age', 'spectacle-prescrip', 'astigmatism', 'tear-prod-rate', 'contact-lenses']\n",
      "Number of entries: 15\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesian(verbose=False)\n",
    "model.read_csv('lense_train.txt')\n",
    "model.remove_feature(model.df.columns[0])\n",
    "model.info()\n",
    "model.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-advance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-appendix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cooperative-brick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 31\n",
      "Label: class_label\n",
      "Features: ['no', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesian(verbose=False)\n",
    "df = model.load('mushroom_update.csv')\n",
    "model.prior_dict\n",
    "predictions,dataset = model.predict_file('mushroom_test.txt',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_predictions(predictions,dataset)\n",
    "actualList = dataset[model.label_name]\n",
    "predictionList = np.array(predictions)\n",
    "labels = model.df[model.label_name].unique()\n",
    "report = Report()\n",
    "newList = report.create_cm_list(actualList,predictionList,labels)\n",
    "report.create_report(newList,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "continuous-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def multi_level_dict():\n",
    "    \"\"\" Constructor for creating multi-level nested dictionary. \"\"\"\n",
    "\n",
    "    return defaultdict(multi_level_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "economic-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file/student_model.csv')\n",
    "data = []\n",
    "model_list = multi_level_dict()\n",
    "for index in df.index:\n",
    "    feature_class= df['feature'][index]\n",
    "    feature_value = df['X'][index]\n",
    "    label = df['C'][index]\n",
    "    feature_suppot_count = df['Xi'][index]\n",
    "    label_support_count = df['Ci'][index]\n",
    "    label_count = df['FeatureType'][index]\n",
    "    prior = Prior(feature_value, label,feature_suppot_count,label_support_count,label_count)\n",
    "    model_list[feature_class][feature_value][label] = prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "pediatric-billy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': {'young': {'none': <__main__.Prior at 0x1e1ff88a280>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff8877f0>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff68d8b0>},\n",
       "  'pre-presbyopic': {'none': <__main__.Prior at 0x1e1ff68dca0>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff887490>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff68ea90>},\n",
       "  'prebyopic': {'none': <__main__.Prior at 0x1e1ff826670>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff826940>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff85cfa0>}},\n",
       " 'spectacle-prescrip': {'myope': {'none': <__main__.Prior at 0x1e1ff5823a0>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff887640>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff5820d0>},\n",
       "  'hypermetrope': {'none': <__main__.Prior at 0x1e1ff887c10>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff68d6a0>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff8879a0>}},\n",
       " 'astigmatism': {'no': {'none': <__main__.Prior at 0x1e1ff68db50>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff68d4f0>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff68d460>},\n",
       "  'yes': {'none': <__main__.Prior at 0x1e1ff6e3d60>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff6e3370>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff889520>}},\n",
       " 'tear-prod-rate': {'reduced': {'none': <__main__.Prior at 0x1e1ff887400>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff889400>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff8879d0>},\n",
       "  'normal': {'none': <__main__.Prior at 0x1e1ff889eb0>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff889490>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff88a6d0>}},\n",
       " 'contact-lenses': {'none': {'none': <__main__.Prior at 0x1e1ff88a100>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff88a130>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff88a310>},\n",
       "  'soft': {'none': <__main__.Prior at 0x1e1ff88a370>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff88a700>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff88a790>},\n",
       "  'hard': {'none': <__main__.Prior at 0x1e1ff88a850>,\n",
       "   'soft': <__main__.Prior at 0x1e1ff88a8e0>,\n",
       "   'hard': <__main__.Prior at 0x1e1ff88a970>}}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prior_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dress-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youth no 3 4 2 0.75\n",
      "youth yes 1 6 2 0.16666666666666666\n",
      "middle_aged no 0 4 2 0.16666666666666666\n",
      "middle_aged yes 2 6 2 0.3333333333333333\n",
      "senior no 1 4 2 0.25\n",
      "senior yes 3 6 2 0.5\n",
      "high no 2 4 2 0.5\n",
      "high yes 1 6 2 0.16666666666666666\n",
      "medium no 1 4 2 0.25\n",
      "medium yes 2 6 2 0.3333333333333333\n",
      "low no 1 4 2 0.25\n",
      "low yes 3 6 2 0.5\n",
      "no no 3 4 2 0.75\n",
      "no yes 2 6 2 0.3333333333333333\n",
      "yes no 1 4 2 0.25\n",
      "yes yes 4 6 2 0.6666666666666666\n",
      "fair no 2 4 2 0.5\n",
      "fair yes 5 6 2 0.8333333333333334\n",
      "excellent no 2 4 2 0.5\n",
      "excellent yes 1 6 2 0.16666666666666666\n",
      "no no 4 4 2 1.0\n",
      "no yes 0 6 2 0.125\n",
      "yes no 0 4 2 0.16666666666666666\n",
      "yes yes 6 6 2 1.0\n"
     ]
    }
   ],
   "source": [
    "for class_key in model_list:\n",
    "    class_value = model_list[class_key]\n",
    "    for label_value in class_value:\n",
    "        objs = class_value[label_value]\n",
    "        for key in objs:\n",
    "            obj = objs[key]\n",
    "            print(obj.feature,obj.label,obj.feature_support,obj.label_support,obj.label_count,obj.probability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "presidential-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                          1837\n",
       "cap-shape                      x\n",
       "cap-surface                    y\n",
       "cap-color                      n\n",
       "bruises                        t\n",
       "odor                           n\n",
       "gill-attachment                f\n",
       "gill-spacing                   c\n",
       "gill-size                      b\n",
       "gill-color                     w\n",
       "stalk-shape                    t\n",
       "stalk-root                     b\n",
       "stalk-surface-above-ring       s\n",
       "stalk-surface-below-ring       s\n",
       "stalk-color-above-ring         p\n",
       "stalk-color-below-ring         g\n",
       "veil-type                      p\n",
       "veil-color                     w\n",
       "ring-number                    o\n",
       "ring-type                      p\n",
       "spore-print-color              n\n",
       "population                     y\n",
       "habitat                        d\n",
       "class_label                    e\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "serial-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 2\n",
      "Label: contact-lenses\n",
      "Features: ['NO', 'Age', 'spectacle-prescrip', 'astigmatism', 'tear-prod-rate']\n"
     ]
    }
   ],
   "source": [
    "predictions,dataset = model.predict_file('lense_test.txt',verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
