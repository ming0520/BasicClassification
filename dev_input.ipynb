{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "powered-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from anytree import Node, RenderTree, find, Walker,DoubleStyle,LevelOrderIter,findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedicated-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, name=None, unique=None,info=0.0,\n",
    "                 df=None,gain=0.0,split_info=0.0):\n",
    "        \n",
    "        self.name = name\n",
    "        self.unique = unique\n",
    "        self.info = info\n",
    "        self.gain = gain\n",
    "        self.split_info = split_info\n",
    "        self.gain_ratio = 0.0\n",
    "        self.dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureVector:\n",
    "#     def __init__(feature=None,label=None,count=0):\n",
    "#         self.feature = feature\n",
    "#         self.label = label\n",
    "#         self.count = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "intimate-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C45:\n",
    "    def __init__(self):\n",
    "        self.except_features = []\n",
    "        self.feature_list={}\n",
    "        self.selected_feature=[]\n",
    "        self.tree = None\n",
    "        self.ROOT = 'root'\n",
    "        self.LABEL = 'label'\n",
    "        self.DECISION = 'class'\n",
    "        self.VALUE = 'value'        \n",
    "        \n",
    "    def read_csv(self,filename):\n",
    "        df = pd.read_table(filename, sep=';', engine='python')\n",
    "        self.label_name = df.columns[-1]\n",
    "        self.number_of_entries = len(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def remove_feature(self,feature):\n",
    "        if feature not in self.except_features:\n",
    "            self.except_features.append(feature)\n",
    "            self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "#             self.df = self.df.drop(feature,axis=1)\n",
    "        else:\n",
    "            print(f'{feature} is removed!')\n",
    "        \n",
    "    def identify_feature(self):\n",
    "        except_features = self.except_features\n",
    "        df = self.df\n",
    "        for col in df:\n",
    "            if col not in except_features:\n",
    "                feature = Feature(name=col,unique=df[col].unique())\n",
    "                self.feature_list[col] = feature\n",
    "#         for key in self.feature_list:\n",
    "#             subdf = self.df[[key,self.label_name]]\n",
    "#             self.feature_list[key].dataset = subdf\n",
    "    \n",
    "    def log2(self,x):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return math.log(x,2)\n",
    "        \n",
    "    def calc_info(self,featureObj,labelObj,df):\n",
    "#         print(f'Processing {featureObj.name}')\n",
    "        number_of_entries = len(df)\n",
    "        sum_info = 0.0\n",
    "        classP = 0.0\n",
    "        if featureObj == labelObj:\n",
    "            info = 0.0\n",
    "            for label_value in labelObj.unique:\n",
    "                idxs = df[(df[labelObj.name]==label_value)].index\n",
    "                occur = len(idxs)\n",
    "#                 print('occur:',occur)\n",
    "                valueP = float(occur)/number_of_entries\n",
    "                info = info - (valueP * ( self.log2(valueP) ) )\n",
    "            return info\n",
    "        \n",
    "        for feature_value in featureObj.unique:\n",
    "            info = 0.0\n",
    "            idxs = df[(df[featureObj.name]==feature_value)].index\n",
    "            Dj = len(idxs)\n",
    "#             print(f'Occurance: {Dj}, ClassP: {classP}')\n",
    "            classP = float(Dj)/number_of_entries\n",
    "            for label_value in labelObj.unique:\n",
    "                idxs = df[(df[featureObj.name]==feature_value) & (df[labelObj.name]==label_value)].index\n",
    "                occur = len(idxs)\n",
    "#                 print(f'{feature_value} {label_value} {occur}/{Dj}')\n",
    "                if(Dj != 0.0):\n",
    "                    valueP = float(occur)/Dj\n",
    "                else:\n",
    "                    valueP = 0.0\n",
    "                info = info - (valueP * ( self.log2(valueP) ) )\n",
    "            split_info = classP * info\n",
    "            sum_info = sum_info + split_info\n",
    "#         print(f'Info {featureObj.name}(D) = {sum_info}')\n",
    "#         print('========================================================')\n",
    "        return sum_info\n",
    "\n",
    "    def find_feature(self,dataset):\n",
    "        feature_list = {}\n",
    "        for col in dataset:\n",
    "            if col not in self.except_features:\n",
    "                feature = Feature(name=col,unique=dataset[col].unique())\n",
    "                feature_list[col] = feature\n",
    "        return feature_list\n",
    "\n",
    "    def best_feature(self,feature_list):\n",
    "        bestGain = 0.0\n",
    "        for key in feature_list: \n",
    "            featureObj = feature_list[key]\n",
    "            if featureObj.gain_ratio > bestGain:\n",
    "                bestFeature = featureObj\n",
    "                bestGain = featureObj.gain_ratio\n",
    "        if bestGain == 0.0:\n",
    "            return -99\n",
    "        return bestFeature\n",
    "    \n",
    "    def find_best_features(self,feature_list,df):\n",
    "        labelObj = feature_list[self.label_name]\n",
    "        for key in feature_list:\n",
    "            featureObj = feature_list[key]\n",
    "            featureObj.info = self.calc_info(featureObj,labelObj,df)\n",
    "            featureObj.split_info = self.calc_info(featureObj,featureObj,df)\n",
    "        labelObj = feature_list[self.label_name]\n",
    "        for key in feature_list:\n",
    "            featureObj = feature_list[key]\n",
    "            if featureObj == labelObj:\n",
    "                continue\n",
    "            featureObj.gain = labelObj.info - featureObj.info\n",
    "            if(featureObj.gain != 0.0):\n",
    "                featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "            else:\n",
    "                featureObj.gain_ratio = 0.0\n",
    "            print(f'{featureObj.name} info={featureObj.info:.4f} gain={featureObj.gain:.4f} split_info={featureObj.split_info:.4f} gain_ratio={featureObj.gain_ratio:.4f}')\n",
    "        return feature_list\n",
    "\n",
    "    def find_best_label(self,labelObj,df):\n",
    "        count = 0\n",
    "        bestLabel = labelObj.unique[0]\n",
    "        for value in labelObj.unique:\n",
    "            idxs = df[(df[labelObj.name]==value)].index\n",
    "            newCount = len(idxs)\n",
    "            if newCount > count:\n",
    "                bestLabel = value\n",
    "        return bestLabel\n",
    "    \n",
    "    def split_dataset(self,name,value,dataset):\n",
    "        dataset = dataset.loc[(dataset[name]==value)]\n",
    "        dataset = dataset.drop(name,axis=1)\n",
    "        return dataset\n",
    "    \n",
    "    def create_value_node(self,feature,df,currentNode):\n",
    "        for value in feature.unique:\n",
    "            dataset = self.split_dataset(feature.name,value,df)\n",
    "            newNode = Node(value,parent=currentNode,dataset=dataset,type=self.VALUE)\n",
    "            \n",
    "    def create_tree(self):\n",
    "        # feature_list = model.feature_list\n",
    "        print('Identifing first feature...')\n",
    "        feature_list = self.find_feature(self.df)\n",
    "        feature_list = self.find_best_features(feature_list,self.df)\n",
    "        bestFeature = self.best_feature(feature_list)\n",
    "        root = Node(bestFeature.name,type=self.ROOT)\n",
    "        print(f'Best feature: {bestFeature.name}')\n",
    "        for value in bestFeature.unique:\n",
    "            dataset = self.split_dataset(bestFeature.name,value,self.df)\n",
    "        #     dataset = model.df.loc[(model.df[bestFeature.name]==value)]\n",
    "        #     dataset = dataset.drop(bestFeature.name,axis=1)\n",
    "            newNode = Node(value,parent=root,dataset=dataset,type=self.VALUE)\n",
    "        self.tree = root\n",
    "        self.display_tree()\n",
    "        for node in LevelOrderIter(root):\n",
    "            print('=================================')\n",
    "            print(f'Node: {node.name} Type:{node.type}')\n",
    "            if node != root and node.type != self.LABEL and node.type != self.DECISION:\n",
    "        #         print(f'Node: {node.name}')\n",
    "                print(node.dataset)\n",
    "                feature_list = self.find_feature(node.dataset)\n",
    "#                 print(f'Length: {len(feature_list)}')\n",
    "                feature_list = self.find_best_features(feature_list,node.dataset)\n",
    "                bestFeature = self.best_feature(feature_list)\n",
    "                if(bestFeature != -99):\n",
    "                    print(f\"Best feature: {bestFeature.name}\")\n",
    "                    newNode = Node(bestFeature.name,parent=node,type=self.DECISION)\n",
    "                    self.create_value_node(bestFeature,node.dataset,newNode)\n",
    "                else:\n",
    "                    labelObj = feature_list[model.label_name]\n",
    "                    best_label = self.find_best_label(labelObj,node.dataset)\n",
    "                    print(f'Selected label: {best_label}')\n",
    "                    newNode = Node(best_label,parent=node,type=self.LABEL)\n",
    "                self.display_tree()\n",
    "            else:\n",
    "                print(f'Skip {node.name} {node.type}')\n",
    "                continue\n",
    "        return root\n",
    "    \n",
    "    def read_testset(self,file):\n",
    "        df = pd.read_table(file, sep=';', engine='python')\n",
    "        label_name = df.columns[-1]\n",
    "        number_of_entries = len(df)\n",
    "        features = [item for item in df.columns if item != label_name]\n",
    "        return label_name,number_of_entries,df,features\n",
    "    \n",
    "    def check_value(self,currentNode,data):\n",
    "        if currentNode.type == self.LABEL:\n",
    "            return currentNode\n",
    "        for child in currentNode.children:\n",
    "    #         print(f'Data:{str(data[currentNode.name])} type({type(str(data[currentNode.name]))}) compare child {str(child.name)} type({type(str(child.name))})')\n",
    "            if(str(data[currentNode.name]) == str(child.name)):\n",
    "                found = True\n",
    "                return child\n",
    "            \n",
    "    def get_label(self,data):\n",
    "        #initialize with root of tree\n",
    "        currentNode = self.tree\n",
    "        #start to find prediction\n",
    "        while True:\n",
    "    #         print(currentNode.name,currentNode.type)\n",
    "    #         if it is label mean leaf\n",
    "            if currentNode.type == self.LABEL:\n",
    "                return currentNode.name\n",
    "            #keep decending\n",
    "            valueNode = self.check_value(currentNode,data)\n",
    "            # if it is leaf return result\n",
    "    #         if valueNode.type == model.LABEL:\n",
    "    #             return valueNode.name\n",
    "            #go to next node\n",
    "            currentNode = valueNode.children[0]\n",
    "            \n",
    "    def predict_file(self,file):\n",
    "        label_name,number_of_entries,dataset,features = self.read_testset(file)\n",
    "        predictions = []\n",
    "        print(f'Number of entries: {number_of_entries}')\n",
    "        print(f'Label: {label_name}')\n",
    "        print(f'Features: {features}')\n",
    "        for index in dataset.index:\n",
    "            data = dataset.loc[index]\n",
    "            try:\n",
    "                label = self.get_label(data)\n",
    "            except:\n",
    "                label = 'No label'\n",
    "            predictions.append(label)\n",
    "#             print(f'Index: {index}')\n",
    "#             print(f'Actual: {data[model.label_name]}')\n",
    "#             print(f'Predicted: {label}')\n",
    "        return predictions,dataset\n",
    "\n",
    "    def display_predictions(self,predictions,dataset):\n",
    "#         print(dataset.columns[0],self.label_name,'Predictions')\n",
    "        df = pd.DataFrame(columns=[dataset.columns[0],self.label_name,'Predictions'])\n",
    "        df['Predictions'] = predictions\n",
    "        df[dataset.columns[0]]=dataset[dataset.columns[0]]\n",
    "        df[self.label_name]=dataset[self.label_name]\n",
    "        print(df)\n",
    "\n",
    "    def display_tree(self):\n",
    "        for pre,_,node in RenderTree(self.tree,DoubleStyle):\n",
    "                print(\"%s%s\" % (pre, node.name))    \n",
    "        \n",
    "    def display_feature_list(self):\n",
    "        for key in feature_list:\n",
    "            print('======================================')\n",
    "            print(f'Feature name: {feature_list[key].name}')\n",
    "            print(f'Unique: {feature_list[key].unique}')\n",
    "            print(f'Info Value: {feature_list[key].entropy}')\n",
    "            print(f'Dataset: {feature_list[key].dataset}')\n",
    "            print('======================================')\n",
    "                \n",
    "    def info(self):\n",
    "        self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "        print(f'Remove feature: {self.except_features}')\n",
    "        print(f'Available feature: {self.features}')\n",
    "        print(f'Number of entries: {self.number_of_entries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "unlimited-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value(currentNode,data):\n",
    "    found = False\n",
    "    if currentNode.type == model.LABEL:\n",
    "        return currentNode\n",
    "    for child in currentNode.children:\n",
    "        print(f'Data:{str(data[currentNode.name])} type({type(str(data[currentNode.name]))}) compare child {str(child.name)} type({type(str(child.name))})')\n",
    "        if(str(data[currentNode.name]) == str(child.name)):\n",
    "            found = True\n",
    "            return child\n",
    "    if not found:\n",
    "        return currentNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "parallel-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(data):\n",
    "    #initialize with root of tree\n",
    "    currentNode = model.tree\n",
    "    #start to find prediction\n",
    "    while True:\n",
    "        print(currentNode.name,currentNode.type)\n",
    "#         if it is label mean leaf\n",
    "        if currentNode.type == model.LABEL:\n",
    "            print('return')\n",
    "            return currentNode.name\n",
    "        #keep decending\n",
    "        valueNode = check_value(currentNode,data)\n",
    "        if(currentNode == valueNode):\n",
    "            return currentNode\n",
    "        # if it is leaf return result\n",
    "#         if valueNode.type == model.LABEL:\n",
    "#             return valueNode.name\n",
    "        #go to next node\n",
    "        currentNode = valueNode.children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "composed-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp. class\n",
      "Mild value\n",
      "Cool value\n",
      "No label\n",
      "Yes label\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for node in LevelOrderIter(label):\n",
    "    print(node.name,node.type)\n",
    "    labels.append(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "saving-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind root\n",
      "Data:Weak type(<class 'str'>) compare child Strong type(<class 'str'>)\n",
      "Data:Weak type(<class 'str'>) compare child Weak type(<class 'str'>)\n",
      "Outlook class\n",
      "Data:Sunny type(<class 'str'>) compare child Overcast type(<class 'str'>)\n",
      "Data:Sunny type(<class 'str'>) compare child Rain type(<class 'str'>)\n",
      "Data:Sunny type(<class 'str'>) compare child Sunny type(<class 'str'>)\n",
      "Temp. class\n",
      "Data:Hot type(<class 'str'>) compare child Mild type(<class 'str'>)\n",
      "Data:Hot type(<class 'str'>) compare child Cool type(<class 'str'>)\n",
      "Node('/Wind/Weak/Outlook/Sunny/Temp.', type='class')\n"
     ]
    }
   ],
   "source": [
    "label_name,number_of_entries,dataset,features = model.read_testset('golf_test.txt')\n",
    "predictions = []\n",
    "# print(f'Number of entries: {number_of_entries}')\n",
    "# print(f'Label: {label_name}')\n",
    "# print(f'Features: {features}')\n",
    "data = dataset.loc[2]\n",
    "# print(data)\n",
    "label = get_label(data)\n",
    "print(label)\n",
    "# for index in dataset.index:\n",
    "#     data = dataset.loc[index]\n",
    "#     label = model.get_label(data)\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "everyday-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11\n",
      "1    12\n",
      "2    13\n",
      "3    14\n",
      "Name: RID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset[dataset.columns[0]].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "approved-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 3\n",
      "Label: Decision\n",
      "Features: ['Outlook', 'Temp.', 'Humidity', 'Wind']\n",
      "    Outlook Decision Predictions\n",
      "0      Rain      Yes         Yes\n",
      "1  Overcast      Yes         Yes\n",
      "2     Sunny       No    No label\n"
     ]
    }
   ],
   "source": [
    "predictions,dataset = model.predict_file('golf_test.txt')\n",
    "model.display_predictions(predictions,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = C45()\n",
    "model.read_csv('golf_train.txt')\n",
    "model.remove_feature('RID')\n",
    "# model.identify_feature()\n",
    "model.info()\n",
    "print('============================================')\n",
    "model.create_tree()\n",
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sunset-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 4\n",
      "Label: buys_computer\n",
      "Features: ['RID', 'age', 'income', 'student', 'credit_rating']\n",
      "RID buys_computer Predictions\n",
      "11 yes yes\n",
      "12 yes yes\n",
      "13 yes yes\n",
      "14 no no\n"
     ]
    }
   ],
   "source": [
    "predictions,dataset = model.predict_file('student_test.txt')\n",
    "model.display_predictions(predictions,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "formal-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 4\n",
      "Label: buys_computer\n",
      "Features: ['RID', 'age', 'income', 'student', 'credit_rating']\n",
      "11 yes yes\n",
      "12 yes yes\n",
      "13 yes yes\n",
      "14 no no\n"
     ]
    }
   ],
   "source": [
    "predictions,dataset = model.predict_file('student_test.txt')\n",
    "for index in dataset.index:\n",
    "    print(dataset[dataset.columns[0]][index],dataset[model.label_name][index],predictions[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testset(file):\n",
    "    df = pd.read_table(file, sep=';', engine='python')\n",
    "    label_name = df.columns[-1]\n",
    "    number_of_entries = len(df)\n",
    "    features = [item for item in df.columns if item != label_name]\n",
    "    return label_name,number_of_entries,df,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "maritime-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value(currentNode,data):\n",
    "    if currentNode.type == model.LABEL:\n",
    "        return currentNode\n",
    "    for child in currentNode.children:\n",
    "#         print(f'Data:{str(data[currentNode.name])} type({type(str(data[currentNode.name]))}) compare child {str(child.name)} type({type(str(child.name))})')\n",
    "        if(str(data[currentNode.name]) == str(child.name)):\n",
    "            found = True\n",
    "            return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "soviet-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(data):\n",
    "    #initialize with root of tree\n",
    "    currentNode = model.tree\n",
    "    #start to find prediction\n",
    "    while True:\n",
    "#         print(currentNode.name,currentNode.type)\n",
    "#         if it is label mean leaf\n",
    "        if currentNode.type == model.LABEL:\n",
    "            return currentNode.name\n",
    "        #keep decending\n",
    "        valueNode = check_value(currentNode,data)\n",
    "        # if it is leaf return result\n",
    "#         if valueNode.type == model.LABEL:\n",
    "#             return valueNode.name\n",
    "        #go to next node\n",
    "        currentNode = valueNode.children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "civilian-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(file):\n",
    "    label_name,number_of_entries,dataset,features = read_testset(file)\n",
    "    predictions = []\n",
    "    print(f'Number of entries: {number_of_entries}')\n",
    "    print(f'Label: {label_name}')\n",
    "    print(f'Features: {features}')\n",
    "    for index in dataset.index:\n",
    "        data = dataset.loc[index]\n",
    "        try:\n",
    "            label = get_label(data)\n",
    "        except:\n",
    "            label = 'No label'\n",
    "        predictions.append(label)\n",
    "        print(f'Index: {index}')\n",
    "        print(f'Actual: {data[model.label_name]}')\n",
    "        print(f'Predicted: {label}')\n",
    "    return predictions,dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "smart-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 39\n",
      "Label: Class\n",
      "Features: ['age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
      "Index: 0\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 1\n",
      "Actual: no_recurrence_events\n",
      "Predicted: recurrence_events\n",
      "Index: 2\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 3\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 4\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 5\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 6\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 7\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 8\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 9\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 10\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 11\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 12\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 13\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 14\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 15\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 16\n",
      "Actual: no_recurrence_events\n",
      "Predicted: recurrence_events\n",
      "Index: 17\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 18\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 19\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 20\n",
      "Actual: no_recurrence_events\n",
      "Predicted: recurrence_events\n",
      "Index: 21\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 22\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 23\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 24\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 25\n",
      "Actual: no_recurrence_events\n",
      "Predicted: recurrence_events\n",
      "Index: 26\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 27\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 28\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 29\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 30\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 31\n",
      "Actual: no_recurrence_events\n",
      "Predicted: recurrence_events\n",
      "Index: 32\n",
      "Actual: no_recurrence_events\n",
      "Predicted: recurrence_events\n",
      "Index: 33\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 34\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 35\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n",
      "Index: 36\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 37\n",
      "Actual: no_recurrence_events\n",
      "Predicted: no_recurrence_events\n",
      "Index: 38\n",
      "Actual: no_recurrence_events\n",
      "Predicted: No label\n"
     ]
    }
   ],
   "source": [
    "predictions,dataset=predict_file('breast_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# currentNode = root\n",
    "# root = model.tree\n",
    "# found = False;\n",
    "# for index in dataset.index:\n",
    "#         data = dataset[currentNode.name][index]\n",
    "#         found = False\n",
    "#         for child in currentNode.children:\n",
    "#             if (data == child.name):\n",
    "#                 currentNode = child\n",
    "#                 found = True\n",
    "#                 break\n",
    "#         if found:\n",
    "#             currentNode = child\n",
    "#         print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature(feature_list):\n",
    "    bestGain = 0.0\n",
    "    for key in feature_list: \n",
    "        featureObj = feature_list[key]\n",
    "        if featureObj.gain_ratio > bestGain:\n",
    "            bestFeature = featureObj\n",
    "            bestGain = featureObj.gain_ratio\n",
    "    if bestGain == 0.0:\n",
    "        return -99\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_features(feature_list,df):\n",
    "    labelObj = feature_list[model.label_name]\n",
    "    for key in feature_list:\n",
    "        featureObj = feature_list[key]\n",
    "        featureObj.info = model.calc_info(featureObj,labelObj,df)\n",
    "        featureObj.split_info = model.calc_info(featureObj,featureObj,df)\n",
    "    labelObj = feature_list[model.label_name]\n",
    "    for key in feature_list:\n",
    "        featureObj = feature_list[key]\n",
    "        if featureObj == labelObj:\n",
    "            continue\n",
    "        featureObj.gain = labelObj.info - featureObj.info\n",
    "        featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "        print(featureObj.name,featureObj.info,featureObj.gain,featureObj.split_info,featureObj.gain_ratio)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'root'\n",
    "LABEL = 'label'\n",
    "DECISION = 'class'\n",
    "VALUE = 'value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feature(dataset):\n",
    "    feature_list = {}\n",
    "    for col in dataset:\n",
    "        if col not in model.except_features:\n",
    "            feature = Feature(name=col,unique=dataset[col].unique())\n",
    "            feature_list[col] = feature\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_label(labelObj,df):\n",
    "    count = 0\n",
    "    bestLabel = labelObj.unique[0]\n",
    "    for value in labelObj.unique:\n",
    "        idxs = df[(df[labelObj.name]==value)].index\n",
    "        newCount = len(idxs)\n",
    "        if newCount > count:\n",
    "            bestLabel = value\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(name,value,dataset):\n",
    "    dataset = dataset.loc[(dataset[name]==value)]\n",
    "    dataset = dataset.drop(name,axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_value_node(feature,df,currentNode):\n",
    "    for value in feature.unique:\n",
    "        dataset = split_dataset(feature.name,value,df)\n",
    "        newNode = Node(value,parent=currentNode,dataset=dataset,type=VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre,_,node in RenderTree(root,DoubleStyle):\n",
    "        print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = model.feature_list\n",
    "feature_list = find_feature(model.df)\n",
    "feature_list = find_best_features(feature_list,model.df)\n",
    "bestFeature = best_feature(feature_list)\n",
    "root = Node(bestFeature.name,type=ROOT)\n",
    "for value in bestFeature.unique:\n",
    "    dataset = split_dataset(bestFeature.name,value,model.df)\n",
    "#     dataset = model.df.loc[(model.df[bestFeature.name]==value)]\n",
    "#     dataset = dataset.drop(bestFeature.name,axis=1)\n",
    "    newNode = Node(value,parent=root,dataset=dataset,type=VALUE)\n",
    "for node in LevelOrderIter(root):\n",
    "    print(f'Node: {node.name} Type:{node.type}')\n",
    "    if node != root and node.type != LABEL and node.type != DECISION:\n",
    "#         print(f'Node: {node.name}')\n",
    "        print(node.dataset,node.type)\n",
    "        feature_list = find_feature(node.dataset)\n",
    "        print(f'Length: {len(feature_list)}')\n",
    "        feature_list = find_best_features(feature_list,node.dataset)\n",
    "        bestFeature = best_feature(feature_list)\n",
    "        if(bestFeature != -99):\n",
    "            print(f\"Best feature: {bestFeature.name}\")\n",
    "            newNode = Node(bestFeature.name,parent=node,type=DECISION)\n",
    "            create_value_node(bestFeature,node.dataset,newNode)\n",
    "        else:\n",
    "            labelObj = feature_list[model.label_name]\n",
    "            best_label = find_best_label(labelObj,node.dataset)\n",
    "            print(f'Selected label: {best_label}')\n",
    "            newNode = Node(best_label,parent=node,type=LABEL)\n",
    "    print('=================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "## developed for find_best_featrues method\n",
    "# feature_list = model.feature_list\n",
    "# labelObj = feature_list[model.label_name]\n",
    "# selected_features = []\n",
    "# for key in feature_list:\n",
    "#     featureObj = feature_list[key]\n",
    "#     featureObj.info = model.calc_info(featureObj,labelObj,model.df)\n",
    "#     featureObj.split_info = model.calc_info(featureObj,featureObj,model.df)\n",
    "# labelObj = feature_list[model.label_name]\n",
    "# for key in feature_list:\n",
    "#     featureObj = feature_list[key]\n",
    "#     if featureObj == labelObj:\n",
    "#         continue\n",
    "#     featureObj.gain = labelObj.info - featureObj.info\n",
    "#     featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "#     print(featureObj.name,featureObj.info,featureObj.gain,featureObj.split_info,featureObj.gain_ratio)\n",
    "# bestFeature = best_feature(feature_list)\n",
    "# selected_features.append(bestFeature)\n",
    "# print('Best feature:',bestFeature.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "## old find best features method\n",
    "# def find_best_features(feature_list,labelObj,df):\n",
    "#     for key in feature_list:\n",
    "#         featureObj = feature_list[key]\n",
    "#         featureObj.info = model.calc_info(featureObj,labelObj,df)\n",
    "#         featureObj.split_info = model.calc_info(featureObj,featureObj,df)\n",
    "#     for key in feature_list:\n",
    "#         featureObj = feature_list[key]\n",
    "#         if featureObj == labelObj:\n",
    "#             continue\n",
    "#         featureObj.gain = labelObj.info - featureObj.info\n",
    "#         featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "#         print(featureObj.name,featureObj.info,featureObj.gain,featureObj.split_info,featureObj.gain_ratio)\n",
    "#     bestFeature = best_feature(feature_list)\n",
    "#     return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = model.feature_list\n",
    "# feature_list = find_best_features(feature_list,model.df)\n",
    "# bestFeature = best_feature(feature_list)\n",
    "# print('Best feature:',bestFeature.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre,_,node in RenderTree(root,DoubleStyle):\n",
    "    try:\n",
    "        print(\"%s%s\\n%s\" % (pre, node.name,node.dataset))\n",
    "    except:\n",
    "        print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in bestFeature.unique:\n",
    "    print(value)\n",
    "    dataset = model.df.loc[(model.df[bestFeature.name]==value)]\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestFeature.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in feature_list:\n",
    "    print(feature_list[key].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.df\n",
    "number_of_entries = len(df)\n",
    "info = 0.0\n",
    "for label_value in labelObj.unique:\n",
    "    idxs = df[(df[labelObj.name]==label_value)].index\n",
    "    occur = len(idxs)\n",
    "    print('occur:',occur)\n",
    "    valueP = float(occur)/number_of_entries\n",
    "    info = info - (valueP * ( log2(valueP) ) )\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.log(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info(featureObj,labelObj):\n",
    "#     featureObj = model.feature_list['age']\n",
    "#     labelObj = model.feature_list['buys_computer']\n",
    "    print(f'Processing {featureObj.name}')\n",
    "    df = model.df\n",
    "    sum_info = 0.0\n",
    "    classP = 0.0\n",
    "    for feature_value in featureObj.unique:\n",
    "        info = 0.0\n",
    "        idxs = df[(df[featureObj.name]==feature_value)].index\n",
    "        Dj = len(idxs)\n",
    "        print(f'Occurance: {Dj}, ClassP: {classP}')\n",
    "        classP = float(Dj)/model.number_of_entries\n",
    "    #     print(f'{Dj}/{model.number_of_entries}')\n",
    "        for label_value in labelObj.unique:\n",
    "            idxs = df[(df[featureObj.name]==feature_value) & (df[labelObj.name]==label_value)].index\n",
    "            occur = len(idxs)\n",
    "            print(f'{feature_value} {label_value} {occur}/{Dj}')\n",
    "            valueP = float(occur)/Dj\n",
    "            info = info - (valueP * ( log2(valueP) ) )\n",
    "        split_info = classP * info\n",
    "        sum_info = sum_info + split_info\n",
    "    print(f'Info {featureObj.name}(D) = {sum_info}')\n",
    "    print('========================================================')\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelObj = feature_list[model.label_name]\n",
    "for key in feature_list:\n",
    "    featureObj = feature_list[key]\n",
    "    featureObj.info = model.calc_info(featureObj,labelObj,model.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureObj = model.feature_list['age']\n",
    "labelObj = model.feature_list['buys_computer']\n",
    "print(f'Processing {featureObj.name}')\n",
    "sum_info = 0.0\n",
    "for feature_value in featureObj.unique:\n",
    "    info = 0.0\n",
    "    idxs = df[(df[feature_obj.name]==feature_value)].index\n",
    "    Dj = len(idxs)\n",
    "    print(f'Occurance: {Dj}, ClassP: {classP}')\n",
    "    classP = float(Dj)/model.number_of_entries\n",
    "#     print(f'{Dj}/{model.number_of_entries}')\n",
    "    for label_value in labelObj.unique:\n",
    "        idxs = df[(df[feature_obj.name]==feature_value) & (df[label_name]==label_value)].index\n",
    "        occur = len(idxs)\n",
    "        valueP = float(occur)/Dj\n",
    "        info = info - (valueP * ( log2(valueP) ) )\n",
    "        print(feature_value,label_value,occur)\n",
    "    split_info = classP * info\n",
    "    sum_info = sum_info + split_info\n",
    "print(f'Info {featureObj.name}(D) = {sum_info}')\n",
    "print('========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.df\n",
    "feature_list = model.feature_list\n",
    "for key in feature_list:\n",
    "    print(key)\n",
    "    subdf = df[[key,label_name]]\n",
    "    feature_list[key].dataset = subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "feaVec=[]\n",
    "feature_list = model.feature_list\n",
    "label_name = model.label_name\n",
    "df = model.df\n",
    "for key in feature_list:\n",
    "    if key != label_name:\n",
    "        print(f'---{key}---')\n",
    "        feature_obj = feature_list[key]\n",
    "        for feature_value in feature_obj.unique:\n",
    "                print(feature_value)\n",
    "#                 idxs = df[(df[feature_obj.name]==feature_value) & (df[label_name]==label_value)].index\n",
    "#                 subdf = df.loc[(df[feature_obj.name]==feature_value) & (df[label_name]==label_value)]\n",
    "                subdf = df[[feature_obj.name,label_name]]\n",
    "                print(subdf)\n",
    "#                 count = len(dataset)\n",
    "#                 probability = float(count/model.number_of_entries)\n",
    "#                 print(feature_value,label_value,probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-respondent",
   "metadata": {},
   "source": [
    "Developed for read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "except_features = []\n",
    "df = pd.read_table('student_train.txt', sep=';', engine='python')\n",
    "label_name = df.columns[-1]\n",
    "except_features.append('RID')\n",
    "number_of_entries = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(except_features)\n",
    "print(number_of_features,label_name)\n",
    "print(df.columns)\n",
    "print(number_of_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-montana",
   "metadata": {},
   "source": [
    "Identify Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list={}\n",
    "for col in df:\n",
    "    if col not in except_features:\n",
    "        feature = Feature(name=col,unique=df[col].unique())\n",
    "        feature_list[col] = feature\n",
    "#     feature_list[col] = df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in feature_list:\n",
    "    print(feature_list[key].unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-examination",
   "metadata": {},
   "source": [
    "Develop feature vector to count the gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "feaVec=[]\n",
    "for key in feature_list:\n",
    "    if key != label_name:\n",
    "        feature_obj = feature_list[key]\n",
    "        for feature_value in feature_obj.unique:\n",
    "            for label_value in feature_list[label_name].unique:\n",
    "                print(feature_value,label_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-token",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2019/07/how-to-filter-pandas-dataframe.html\n",
    "\n",
    "solution\n",
    "https://discuss.analyticsvidhya.com/t/how-to-resolve-python-error-cannot-compare-a-dtyped-int64-array-with-a-scalar-of-type-bool/73065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_obj = feature_list['age']\n",
    "df[(df[feature_obj.name]==\"youth\") & (df[label_name]=='no')].index\n",
    "## use to split data\n",
    "# df.loc[(df[feature_obj.name]==\"youth\") & (df[label_name]=='no')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
