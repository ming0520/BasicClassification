{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "affiliated-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ConfussionMatrix import Report,ConfussionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "historical-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, name=None, unique=None,info=0.0,\n",
    "                 df=None,gain=0.0,split_info=0.0):\n",
    "        \n",
    "        self.name = name\n",
    "        self.unique = unique\n",
    "        self.info = info\n",
    "        self.gain = gain\n",
    "        self.split_info = split_info\n",
    "        self.gain_ratio = 0.0\n",
    "        self.dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medieval-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior:\n",
    "    def __init__(self, feature=None, label=None,feature_support=0,label_support=0,label_count=0):\n",
    "        self.feature = feature\n",
    "        self.label = label\n",
    "        self.feature_support = feature_support\n",
    "        self.label_support = label_support\n",
    "        self.label_count = label_count\n",
    "    \n",
    "    def probability(self):\n",
    "        feature_support = self.feature_support\n",
    "        label_support = self.label_support\n",
    "        if (label_support == 0):\n",
    "            return 0\n",
    "        elif(feature_support == 0):\n",
    "            feature_support += 1\n",
    "            label_support += self.label_count\n",
    "        return feature_support/label_support\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "reduced-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesian:\n",
    "    def __init__(self,verbose=True):\n",
    "        self.except_features = []\n",
    "        self.feature_list={}\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def read_csv(self,filename):\n",
    "        df = pd.read_table(filename, sep=';', engine='python')\n",
    "        self.label_name = df.columns[-1]\n",
    "        self.number_of_entries = len(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def remove_feature(self,feature):\n",
    "        if feature not in self.except_features:\n",
    "            self.except_features.append(feature)\n",
    "            self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "#             self.df = self.df.drop(feature,axis=1)\n",
    "        else:\n",
    "            print(f'{feature} is removed!')\n",
    "            \n",
    "    def find_feature(self,dataset):\n",
    "        feature_list = {}\n",
    "        for col in dataset:\n",
    "            if col not in self.except_features:\n",
    "                feature = Feature(name=col,unique=dataset[col].unique())\n",
    "                feature_list[col] = feature\n",
    "        return feature_list\n",
    "    \n",
    "    def create_model(self):\n",
    "        feature_list = self.find_feature(self.df)\n",
    "        key_list = list(feature_list)\n",
    "        label_dict = {}\n",
    "        labelObj = feature_list[self.label_name]\n",
    "        for label in labelObj.unique:\n",
    "            label_idxs = self.df[(self.df[labelObj.name]==label)].index\n",
    "            label_dict[label] = len(label_idxs)\n",
    "\n",
    "        prior_dict = {}\n",
    "        labelObj = feature_list[self.label_name]  \n",
    "        for key in feature_list:\n",
    "            featureObj = feature_list[key]\n",
    "            value_dict={}\n",
    "            for unique in featureObj.unique: \n",
    "                unique_list={}\n",
    "                for label in labelObj.unique:\n",
    "                    feature_idxs = model.df[((model.df[featureObj.name]==unique)&(model.df[labelObj.name]==label))].index\n",
    "                    feature_count = len(feature_idxs)\n",
    "                    label_count = label_dict[label]\n",
    "                    prior = Prior(unique, label,feature_count,label_count,len(labelObj.unique))\n",
    "                    unique_list[label] = prior\n",
    "                value_dict[unique] = unique_list\n",
    "            prior_dict[key] = value_dict\n",
    "        self.prior_dict = prior_dict\n",
    "        self.label_dict = label_dict\n",
    "        self._feature_list = feature_list\n",
    "        \n",
    "    def get_model(self):\n",
    "        data = []\n",
    "        for key in self.prior_dict:\n",
    "            value_dict = self.prior_dict[key]\n",
    "            for value_key in value_dict:\n",
    "                label_dict = value_dict[value_key]\n",
    "                for label_key in label_dict:\n",
    "                    prior = label_dict[label_key]\n",
    "                    ls = {'feature':key,\n",
    "                          'X':prior.feature,\n",
    "                          'C':prior.label,\n",
    "                          'Xi':prior.feature_support,\n",
    "                          'Ci':prior.label_support,\n",
    "                          'Probability':prior.probability()\n",
    "                         }\n",
    "                    data.append(ls)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    def save_model(self,file):\n",
    "        df = self.get_model()\n",
    "        df.to_csv(file)\n",
    "        \n",
    "    def read_testset(self,file):\n",
    "        df = pd.read_table(file, sep=';', engine='python')\n",
    "        label_name = df.columns[-1]\n",
    "        number_of_entries = len(df)\n",
    "        features = [item for item in df.columns if item != label_name]\n",
    "        return label_name,number_of_entries,df,features        \n",
    "        \n",
    "    def predict(self,data):\n",
    "        if self.verbose:\n",
    "            print('-----------------------Predict for-----------------------')\n",
    "            print(data)\n",
    "            print()\n",
    "        key_list = list(self.prior_dict)\n",
    "        label_result = {}\n",
    "        for label_key in self.label_dict:\n",
    "            pX = 1.0\n",
    "            if self.verbose:\n",
    "                print(f'Label: {label_key}')\n",
    "            for class_key in key_list:\n",
    "                feature = data[class_key]\n",
    "                feature_dict = self.prior_dict[class_key][feature][label_key]\n",
    "                if self.verbose:\n",
    "                    print(feature,feature_dict.probability())\n",
    "                pX *= feature_dict.probability()\n",
    "            try:\n",
    "                pC = float(pX) * (self.label_dict[label_key]/self.number_of_entries)\n",
    "            except:\n",
    "                pC = 0.0\n",
    "            label_result[label_key] = pC\n",
    "            if self.verbose:\n",
    "                print(f\"P({label_key}|X): {pC} / P(X)\")\n",
    "                print()\n",
    "\n",
    "            bestPc = 0.0\n",
    "            bestKey = list(label_result)[0]\n",
    "            for label_key in label_result:\n",
    "                if(label_result[label_key] > bestPc):\n",
    "                    bestPc = label_result[label_key]\n",
    "                    bestKey = label_key\n",
    "        if self.verbose:\n",
    "            print(f'Selected label: {bestKey}')\n",
    "            print('-----------------------End predict-----------------------')\n",
    "        return bestKey\n",
    "        \n",
    "    def predict_file(self,file,verbose=None):\n",
    "        label_name,number_of_entries,dataset,features = self.read_testset(file)\n",
    "        predictions = []\n",
    "        if verbose == None:\n",
    "            verbose =self.verbose\n",
    "        if verbose:\n",
    "            print(f'Number of entries: {number_of_entries}')\n",
    "            print(f'Label: {label_name}')\n",
    "            print(f'Features: {features}')\n",
    "        for index in dataset.index:\n",
    "            data = dataset.loc[index]\n",
    "            label = self.predict(data)\n",
    "            predictions.append(label)\n",
    "        return predictions,dataset\n",
    "    \n",
    "    def display_predictions(self,predictions,dataset):\n",
    "#         print(dataset.columns[0],self.label_name,'Predictions')\n",
    "        df = pd.DataFrame(columns=[dataset.columns[0],self.label_name,'Predictions'])\n",
    "        df['Predictions'] = predictions\n",
    "        df[dataset.columns[0]]=dataset[dataset.columns[0]]\n",
    "        df[self.label_name]=dataset[self.label_name]\n",
    "        print(df)    \n",
    "    \n",
    "    def info(self):\n",
    "        self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "        print(f'Remove feature: {self.except_features}')\n",
    "        print(f'Available feature: {self.features}')\n",
    "        print(f'Number of entries: {self.number_of_entries}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "statistical-transition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove feature: ['NO']\n",
      "Available feature: ['Age', 'spectacle-prescrip', 'astigmatism', 'tear-prod-rate', 'contact-lenses']\n",
      "Number of entries: 15\n",
      "               feature               X     C  Xi  Ci  Probability\n",
      "0                  Age           young  none   3   8     0.375000\n",
      "1                  Age           young  soft   2   4     0.500000\n",
      "2                  Age           young  hard   1   3     0.333333\n",
      "3                  Age  pre-presbyopic  none   2   8     0.250000\n",
      "4                  Age  pre-presbyopic  soft   1   4     0.250000\n",
      "5                  Age  pre-presbyopic  hard   1   3     0.333333\n",
      "6                  Age       prebyopic  none   3   8     0.375000\n",
      "7                  Age       prebyopic  soft   1   4     0.250000\n",
      "8                  Age       prebyopic  hard   1   3     0.333333\n",
      "9   spectacle-prescrip           myope  none   5   8     0.625000\n",
      "10  spectacle-prescrip           myope  soft   1   4     0.250000\n",
      "11  spectacle-prescrip           myope  hard   3   3     1.000000\n",
      "12  spectacle-prescrip    hypermetrope  none   3   8     0.375000\n",
      "13  spectacle-prescrip    hypermetrope  soft   3   4     0.750000\n",
      "14  spectacle-prescrip    hypermetrope  hard   0   3     0.166667\n",
      "15         astigmatism              no  none   4   8     0.500000\n",
      "16         astigmatism              no  soft   4   4     1.000000\n",
      "17         astigmatism              no  hard   0   3     0.166667\n",
      "18         astigmatism             yes  none   4   8     0.500000\n",
      "19         astigmatism             yes  soft   0   4     0.142857\n",
      "20         astigmatism             yes  hard   3   3     1.000000\n",
      "21      tear-prod-rate         reduced  none   6   8     0.750000\n",
      "22      tear-prod-rate         reduced  soft   0   4     0.142857\n",
      "23      tear-prod-rate         reduced  hard   0   3     0.166667\n",
      "24      tear-prod-rate          normal  none   2   8     0.250000\n",
      "25      tear-prod-rate          normal  soft   4   4     1.000000\n",
      "26      tear-prod-rate          normal  hard   3   3     1.000000\n",
      "27      contact-lenses            none  none   8   8     1.000000\n",
      "28      contact-lenses            none  soft   0   4     0.142857\n",
      "29      contact-lenses            none  hard   0   3     0.166667\n",
      "30      contact-lenses            soft  none   0   8     0.090909\n",
      "31      contact-lenses            soft  soft   4   4     1.000000\n",
      "32      contact-lenses            soft  hard   0   3     0.166667\n",
      "33      contact-lenses            hard  none   0   8     0.090909\n",
      "34      contact-lenses            hard  soft   0   4     0.142857\n",
      "35      contact-lenses            hard  hard   3   3     1.000000\n",
      "Number of entries: 2\n",
      "Label: contact-lenses\n",
      "Features: ['NO', 'Age', 'spectacle-prescrip', 'astigmatism', 'tear-prod-rate']\n",
      "   NO contact-lenses Predictions\n",
      "0  t1           none        none\n",
      "1  t2           none        none\n",
      "-----------------------------\n",
      "Label:none\n",
      "Accuracy: 0.00\n",
      "Error: 0.00\n",
      "Specificity: 0.00\n",
      "Percision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "support: 2\n",
      "TP = 2 FP = 0\n",
      "FN = 0 TP = 0\n",
      "-----------------------------\n",
      "Label:soft\n",
      "Accuracy: 0.00\n",
      "Error: 0.00\n",
      "Specificity: 1.00\n",
      "Percision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "support: 0\n",
      "TP = 0 FP = 0\n",
      "FN = 0 TP = 2\n",
      "-----------------------------\n",
      "Label:hard\n",
      "Accuracy: 0.00\n",
      "Error: 0.00\n",
      "Specificity: 1.00\n",
      "Percision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "support: 0\n",
      "TP = 0 FP = 0\n",
      "FN = 0 TP = 2\n",
      "-----------------------------\n",
      "Micro f1/Accuracy: 1.00\n",
      "Macro f1: 0.33\n",
      "Weighted f1: 1.00\n",
      "Micro error: 0.00\n",
      "Macro error: 0.00\n",
      "Weighted error: 0.00\n",
      "Micro percision: 1.00\n",
      "Macro percision: 0.33\n",
      "Weighted percision: 1.00\n",
      "Micro recall: 1.00\n",
      "Macro recall: 0.33\n",
      "Weighted recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesian(verbose=False)\n",
    "model.read_csv('lense_train.txt')\n",
    "model.remove_feature(model.df.columns[0])\n",
    "model.info()\n",
    "model.create_model()\n",
    "print(model.get_model())\n",
    "predictions,dataset = model.predict_file('lense_test.txt',verbose=True)\n",
    "model.display_predictions(predictions,dataset)\n",
    "actualList = dataset[model.label_name]\n",
    "predictionList = np.array(predictions)\n",
    "labels = model.df[model.label_name].unique()\n",
    "report = Report()\n",
    "newList = report.create_cm_list(actualList,predictionList,labels)\n",
    "report.create_report(newList,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compressed-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testset(file):\n",
    "    df = pd.read_table(file, sep=';', engine='python')\n",
    "    label_name = df.columns[-1]\n",
    "    number_of_entries = len(df)\n",
    "    features = [item for item in df.columns if item != label_name]\n",
    "    return label_name,number_of_entries,df,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consolidated-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    print('-----------------------Predict for-----------------------')\n",
    "    print(data)\n",
    "    print()\n",
    "    key_list = list(model.prior_dict)\n",
    "    label_result = {}\n",
    "    for label_key in model.label_dict:\n",
    "        pX = 1.0\n",
    "        print(f'Label: {label_key}')\n",
    "        for class_key in key_list:\n",
    "            feature = data[class_key]\n",
    "            feature_dict = model.prior_dict[class_key][feature][label_key]\n",
    "            print(feature,feature_dict.probability())\n",
    "            pX *= feature_dict.probability()\n",
    "        try:\n",
    "            pC = float(pX) * (model.label_dict[label_key]/model.number_of_entries)\n",
    "        except:\n",
    "            pC = 0.0\n",
    "        label_result[label_key] = pC\n",
    "        print(f\"P({label_key}|X): {pC} / P(X)\")\n",
    "        print()\n",
    "\n",
    "        bestPc = 0.0\n",
    "        bestKey = list(label_result)[0]\n",
    "        for label_key in label_result:\n",
    "            if(label_result[label_key] > bestPc):\n",
    "                bestPc = label_result[label_key]\n",
    "                bestKey = label_key\n",
    "    print(f'Selected label: {bestKey}')\n",
    "    return bestKey\n",
    "    print('-----------------------End predict-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "intense-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = model.find_feature(model.df)\n",
    "key_list = list(feature_list)\n",
    "label_dict = {}\n",
    "for label in labelObj.unique:\n",
    "    label_idxs = model.df[(model.df[labelObj.name]==label)].index\n",
    "    label_dict[label] = len(label_idxs)\n",
    "    \n",
    "prior_dict = {}\n",
    "labelObj = feature_list[model.label_name]  \n",
    "for key in feature_list:\n",
    "    featureObj = feature_list[key]\n",
    "    value_dict={}\n",
    "    for unique in featureObj.unique: \n",
    "        unique_list={}\n",
    "        for label in labelObj.unique:\n",
    "            feature_idxs = model.df[((model.df[featureObj.name]==unique)&(model.df[labelObj.name]==label))].index\n",
    "            feature_count = len(feature_idxs)\n",
    "            label_count = label_dict[label]\n",
    "            prior = Prior(unique, label,feature_count,label_count,len(labelObj.unique))\n",
    "            unique_list[label] = prior\n",
    "        value_dict[unique] = unique_list\n",
    "    prior_dict[key] = value_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
