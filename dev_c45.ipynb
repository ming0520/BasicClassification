{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from anytree import Node, RenderTree, find, Walker,DoubleStyle,LevelOrderIter,findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, name=None, unique=None,info=0.0,\n",
    "                 df=None,gain=0.0,split_info=0.0):\n",
    "        \n",
    "        self.name = name\n",
    "        self.unique = unique\n",
    "        self.info = info\n",
    "        self.gain = gain\n",
    "        self.split_info = split_info\n",
    "        self.gain_ratio = 0.0\n",
    "        self.dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C45:\n",
    "    def __init__(self):\n",
    "        self.except_features = []\n",
    "        self.feature_list={}\n",
    "        self.selected_feature=[]\n",
    "        self.tree = None\n",
    "        self.ROOT = 'root'\n",
    "        self.LABEL = 'label'\n",
    "        self.DECISION = 'class'\n",
    "        self.VALUE = 'value'        \n",
    "        \n",
    "    def read_csv(self,filename):\n",
    "        df = pd.read_table(filename, sep=';', engine='python')\n",
    "        self.label_name = df.columns[-1]\n",
    "        self.number_of_entries = len(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def remove_feature(self,feature):\n",
    "        if feature not in self.except_features:\n",
    "            self.except_features.append(feature)\n",
    "            self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "#             self.df = self.df.drop(feature,axis=1)\n",
    "        else:\n",
    "            print(f'{feature} is removed!')\n",
    "        \n",
    "    def identify_feature(self):\n",
    "        except_features = self.except_features\n",
    "        df = self.df\n",
    "        for col in df:\n",
    "            if col not in except_features:\n",
    "                feature = Feature(name=col,unique=df[col].unique())\n",
    "                self.feature_list[col] = feature\n",
    "#         for key in self.feature_list:\n",
    "#             subdf = self.df[[key,self.label_name]]\n",
    "#             self.feature_list[key].dataset = subdf\n",
    "    \n",
    "    def log2(self,x):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return math.log(x,2)\n",
    "        \n",
    "    def calc_info(self,featureObj,labelObj,df):\n",
    "#         print(f'Processing {featureObj.name}')\n",
    "        number_of_entries = len(df)\n",
    "        sum_info = 0.0\n",
    "        classP = 0.0\n",
    "        if featureObj == labelObj:\n",
    "            info = 0.0\n",
    "            for label_value in labelObj.unique:\n",
    "                idxs = df[(df[labelObj.name]==label_value)].index\n",
    "                occur = len(idxs)\n",
    "#                 print('occur:',occur)\n",
    "                valueP = float(occur)/number_of_entries\n",
    "                info = info - (valueP * ( self.log2(valueP) ) )\n",
    "            return info\n",
    "        \n",
    "        for feature_value in featureObj.unique:\n",
    "            info = 0.0\n",
    "            idxs = df[(df[featureObj.name]==feature_value)].index\n",
    "            Dj = len(idxs)\n",
    "#             print(f'Occurance: {Dj}, ClassP: {classP}')\n",
    "            classP = float(Dj)/number_of_entries\n",
    "            for label_value in labelObj.unique:\n",
    "                idxs = df[(df[featureObj.name]==feature_value) & (df[labelObj.name]==label_value)].index\n",
    "                occur = len(idxs)\n",
    "#                 print(f'{feature_value} {label_value} {occur}/{Dj}')\n",
    "                if(Dj != 0.0):\n",
    "                    valueP = float(occur)/Dj\n",
    "                else:\n",
    "                    valueP = 0.0\n",
    "                info = info - (valueP * ( self.log2(valueP) ) )\n",
    "            split_info = classP * info\n",
    "            sum_info = sum_info + split_info\n",
    "#         print(f'Info {featureObj.name}(D) = {sum_info}')\n",
    "#         print('========================================================')\n",
    "        return sum_info\n",
    "\n",
    "    def find_feature(self,dataset):\n",
    "        feature_list = {}\n",
    "        for col in dataset:\n",
    "            if col not in self.except_features:\n",
    "                feature = Feature(name=col,unique=dataset[col].unique())\n",
    "                feature_list[col] = feature\n",
    "        return feature_list\n",
    "\n",
    "    def best_feature(self,feature_list):\n",
    "        bestGain = 0.0\n",
    "        for key in feature_list: \n",
    "            featureObj = feature_list[key]\n",
    "            if featureObj.gain_ratio > bestGain:\n",
    "                bestFeature = featureObj\n",
    "                bestGain = featureObj.gain_ratio\n",
    "        if bestGain == 0.0:\n",
    "            return -99\n",
    "        return bestFeature\n",
    "    \n",
    "    def find_best_features(self,feature_list,df):\n",
    "        labelObj = feature_list[self.label_name]\n",
    "        for key in feature_list:\n",
    "            featureObj = feature_list[key]\n",
    "            featureObj.info = self.calc_info(featureObj,labelObj,df)\n",
    "            featureObj.split_info = self.calc_info(featureObj,featureObj,df)\n",
    "        labelObj = feature_list[self.label_name]\n",
    "        for key in feature_list:\n",
    "            featureObj = feature_list[key]\n",
    "            if featureObj == labelObj:\n",
    "                continue\n",
    "            featureObj.gain = labelObj.info - featureObj.info\n",
    "            if(featureObj.gain != 0.0):\n",
    "                featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "            else:\n",
    "                featureObj.gain_ratio = 0.0\n",
    "            print(f'{featureObj.name} info={featureObj.info:.4f} gain={featureObj.gain:.4f} split_info={featureObj.split_info:.4f} gain_ratio={featureObj.gain_ratio:.4f}')\n",
    "        return feature_list\n",
    "\n",
    "    def find_best_label(self,labelObj,df):\n",
    "        count = 0\n",
    "        bestLabel = labelObj.unique[0]\n",
    "        for value in labelObj.unique:\n",
    "            idxs = df[(df[labelObj.name]==value)].index\n",
    "            newCount = len(idxs)\n",
    "            if newCount > count:\n",
    "                bestLabel = value\n",
    "        return bestLabel\n",
    "    \n",
    "    def split_dataset(self,name,value,dataset):\n",
    "        dataset = dataset.loc[(dataset[name]==value)]\n",
    "        dataset = dataset.drop(name,axis=1)\n",
    "        return dataset\n",
    "    \n",
    "    def create_value_node(self,feature,df,currentNode):\n",
    "        for value in feature.unique:\n",
    "            dataset = self.split_dataset(feature.name,value,df)\n",
    "            newNode = Node(value,parent=currentNode,dataset=dataset,type=self.VALUE)\n",
    "            \n",
    "    def create_tree(self):\n",
    "        # feature_list = model.feature_list\n",
    "        print('Identifing first feature...')\n",
    "        feature_list = self.find_feature(self.df)\n",
    "        feature_list = self.find_best_features(feature_list,self.df)\n",
    "        bestFeature = self.best_feature(feature_list)\n",
    "        root = Node(bestFeature.name,type=self.ROOT)\n",
    "        print(f'Best feature: {bestFeature.name}')\n",
    "        for value in bestFeature.unique:\n",
    "            dataset = self.split_dataset(bestFeature.name,value,self.df)\n",
    "        #     dataset = model.df.loc[(model.df[bestFeature.name]==value)]\n",
    "        #     dataset = dataset.drop(bestFeature.name,axis=1)\n",
    "            newNode = Node(value,parent=root,dataset=dataset,type=self.VALUE)\n",
    "        self.tree = root\n",
    "        self.display_tree()\n",
    "        for node in LevelOrderIter(root):\n",
    "            print('=================================')\n",
    "            print(f'Node: {node.name} Type:{node.type}')\n",
    "            if node != root and node.type != self.LABEL and node.type != self.DECISION:\n",
    "        #         print(f'Node: {node.name}')\n",
    "                print(node.dataset)\n",
    "                feature_list = self.find_feature(node.dataset)\n",
    "#                 print(f'Length: {len(feature_list)}')\n",
    "                feature_list = self.find_best_features(feature_list,node.dataset)\n",
    "                bestFeature = self.best_feature(feature_list)\n",
    "                if(bestFeature != -99):\n",
    "                    print(f\"Best feature: {bestFeature.name}\")\n",
    "                    newNode = Node(bestFeature.name,parent=node,type=self.DECISION)\n",
    "                    self.create_value_node(bestFeature,node.dataset,newNode)\n",
    "                else:\n",
    "                    labelObj = feature_list[model.label_name]\n",
    "                    best_label = self.find_best_label(labelObj,node.dataset)\n",
    "                    print(f'Selected label: {best_label}')\n",
    "                    newNode = Node(best_label,parent=node,type=self.LABEL)\n",
    "                self.display_tree()\n",
    "            else:\n",
    "                print(f'Skip {node.name} {node.type}')\n",
    "                continue\n",
    "        return root\n",
    "    \n",
    "    def read_testset(self,file):\n",
    "        df = pd.read_table(file, sep=';', engine='python')\n",
    "        label_name = df.columns[-1]\n",
    "        number_of_entries = len(df)\n",
    "        features = [item for item in df.columns if item != label_name]\n",
    "        return label_name,number_of_entries,df,features\n",
    "    \n",
    "    def check_value(self,currentNode,data):\n",
    "        found = False\n",
    "        if currentNode.type == self.LABEL:\n",
    "            return currentNode\n",
    "        for child in currentNode.children:\n",
    "    #         print(f'Data:{str(data[currentNode.name])} type({type(str(data[currentNode.name]))}) compare child {str(child.name)} type({type(str(child.name))})')\n",
    "            if(str(data[currentNode.name]) == str(child.name)):\n",
    "                found = True\n",
    "                return child\n",
    "        if not found:\n",
    "            return currentNode\n",
    "\n",
    "    def get_label(self,data):\n",
    "        #initialize with root of tree\n",
    "        currentNode = self.tree\n",
    "        #start to find prediction\n",
    "        while True:\n",
    "    #         print(currentNode.name,currentNode.type)\n",
    "    #         if it is label mean leaf\n",
    "            if currentNode.type == self.LABEL:\n",
    "                return currentNode.name\n",
    "            #keep decending\n",
    "            valueNode = self.check_value(currentNode,data)\n",
    "            if(currentNode == valueNode):\n",
    "#                 print(f'Missing id={data.values[0]} data={data[currentNode.name]}')\n",
    "                return self.missing_get_label(currentNode)\n",
    "            # if it is leaf return result\n",
    "    #         if valueNode.type == model.LABEL:\n",
    "    #             return valueNode.name\n",
    "            #go to next node\n",
    "            currentNode = valueNode.children[0]\n",
    "            \n",
    "    def missing_get_label(self,currentNode):\n",
    "        labels = []\n",
    "        for node in LevelOrderIter(currentNode):\n",
    "    #         print(node.name,node.type)\n",
    "            if(node.type == self.LABEL):\n",
    "                labels.append(node.name)\n",
    "        labels = np.array(labels)\n",
    "        unique_label = np.unique(labels)\n",
    "        label_list = {}\n",
    "    #     print(labels)\n",
    "    #     print(unique_label)\n",
    "        for item in unique_label:\n",
    "            mask = np.isin(labels,item)\n",
    "            label_list[item] = len(idxs)\n",
    "    #         print(item,len(idxs))\n",
    "        bestLabel = self.missing_best_label(label_list)\n",
    "        return bestLabel\n",
    "            \n",
    "    def missing_best_label(self,label_list):\n",
    "        key_list = list(label_list)\n",
    "    #     print(key_list)\n",
    "        bestLabel = label_list[key_list[0]]\n",
    "        bestCount = 0\n",
    "        for key in key_list:\n",
    "            labelCount = label_list[key]\n",
    "            if(labelCount > bestCount):\n",
    "                bestCount = labelCount\n",
    "    #             print(key,bestCount)\n",
    "        return key\n",
    "            \n",
    "    def predict_file(self,file):\n",
    "        label_name,number_of_entries,dataset,features = self.read_testset(file)\n",
    "        predictions = []\n",
    "#         print(f'Number of entries: {number_of_entries}')\n",
    "#         print(f'Label: {label_name}')\n",
    "#         print(f'Features: {features}')\n",
    "        for index in dataset.index:\n",
    "            data = dataset.loc[index]\n",
    "            label = self.get_label(data)\n",
    "            predictions.append(label)\n",
    "#             print(f'Index: {index}')\n",
    "#             print(f'Actual: {data[model.label_name]}')\n",
    "#             print(f'Predicted: {label}')\n",
    "        return predictions,dataset\n",
    "\n",
    "    def display_predictions(self,predictions,dataset):\n",
    "#         print(dataset.columns[0],self.label_name,'Predictions')\n",
    "        df = pd.DataFrame(columns=[dataset.columns[0],self.label_name,'Predictions'])\n",
    "        df['Predictions'] = predictions\n",
    "        df[dataset.columns[0]]=dataset[dataset.columns[0]]\n",
    "        df[self.label_name]=dataset[self.label_name]\n",
    "        print(df)\n",
    "\n",
    "    def display_tree(self):\n",
    "        for pre,_,node in RenderTree(self.tree,DoubleStyle):\n",
    "                print(\"%s%s\" % (pre, node.name))    \n",
    "        \n",
    "    def display_feature_list(self):\n",
    "        for key in feature_list:\n",
    "            print('======================================')\n",
    "            print(f'Feature name: {feature_list[key].name}')\n",
    "            print(f'Unique: {feature_list[key].unique}')\n",
    "            print(f'Info Value: {feature_list[key].entropy}')\n",
    "            print(f'Dataset: {feature_list[key].dataset}')\n",
    "            print('======================================')\n",
    "                \n",
    "    def info(self):\n",
    "        self.features = [item for item in self.df.columns if item not in self.except_features]\n",
    "        print(f'Remove feature: {self.except_features}')\n",
    "        print(f'Available feature: {self.features}')\n",
    "        print(f'Number of entries: {self.number_of_entries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = C45()\n",
    "model.read_csv('breast_train.txt')\n",
    "model.remove_feature(model.df.columns[0])\n",
    "# model.identify_feature()\n",
    "model.info()\n",
    "print('============================================')\n",
    "model.create_tree()\n",
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "headed-opinion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RID                 Class           Predictions\n",
      "0     p1  no_recurrence_events  no_recurrence_events\n",
      "1     p2  no_recurrence_events     recurrence_events\n",
      "2     p3  no_recurrence_events  no_recurrence_events\n",
      "3     p4  no_recurrence_events  no_recurrence_events\n",
      "4     p5  no_recurrence_events  no_recurrence_events\n",
      "5     p6  no_recurrence_events     recurrence_events\n",
      "6     p7  no_recurrence_events  no_recurrence_events\n",
      "7     p8  no_recurrence_events  no_recurrence_events\n",
      "8   t225     recurrence_events  no_recurrence_events\n",
      "9   t226     recurrence_events  no_recurrence_events\n",
      "10  t227     recurrence_events     recurrence_events\n",
      "11  t228     recurrence_events  no_recurrence_events\n",
      "12  t229     recurrence_events     recurrence_events\n"
     ]
    }
   ],
   "source": [
    "predictions,dataset = model.predict_file('breast_test.txt')\n",
    "model.display_predictions(predictions,dataset)\n",
    "actualList = dataset[model.label_name]\n",
    "predictionList = np.array(predictions)\n",
    "labels = model.df[model.label_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "lightweight-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 2]\n",
      " [3 2]]\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "no_recurrence_events       0.67      0.75      0.71         8\n",
      "   recurrence_events       0.50      0.40      0.44         5\n",
      "\n",
      "            accuracy                           0.62        13\n",
      "           macro avg       0.58      0.57      0.58        13\n",
      "        weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mingb\\anaconda3\\envs\\pythongpu\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['no_recurrence_events' 'recurrence_events'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "c:\\users\\mingb\\anaconda3\\envs\\pythongpu\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['no_recurrence_events' 'recurrence_events'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1b3ca1152e0>"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(actualList,predictionList,labels)\n",
    "print(cm)\n",
    "print(metrics.classification_report(actualList,predictionList,labels))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "stable-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53125\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(actualList,predictionList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "atmospheric-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['mango','orange','apple'])\n",
    "actualList =np.array(\n",
    "    ['apple','apple','apple','apple','apple','apple','apple',\n",
    "         'apple',\n",
    "         'apple','apple','apple',\n",
    "     'orange','orange','orange','orange','orange','orange','orange','orange',\n",
    "     'orange','orange',\n",
    "     'orange','orange',\n",
    "     'mango','mango','mango','mango','mango','mango','mango','mango','mango',\n",
    "     'mango','mango','mango',\n",
    "     'mango'\n",
    "    ])\n",
    "predictionList =np.array(\n",
    "    ['apple','apple','apple','apple','apple','apple','apple',\n",
    "         'orange',\n",
    "         'mango','mango','mango',\n",
    "     'apple','apple','apple','apple','apple','apple','apple','apple',\n",
    "     'orange','orange',\n",
    "     'mango','mango',\n",
    "     'apple','apple','apple','apple','apple','apple','apple','apple','apple',\n",
    "     'orange','orange','orange',\n",
    "     'mango'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "underlying-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfussionMatrix:\n",
    "    def __init__(self,tp=0,fp=0,fn=0,tn=0,support=0,label=None):\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        self.tn = tn\n",
    "        self.support = support\n",
    "        self.label=label\n",
    "        \n",
    "    def get_p(self):\n",
    "        self.p = self.tp + self.fn\n",
    "        return self.p\n",
    "    \n",
    "    def get_n(self):\n",
    "        self.n = self.fp + self.tn\n",
    "        return self.n\n",
    "    \n",
    "    def accuracy(self):\n",
    "        p = self.get_p()\n",
    "        n = self.get_n()\n",
    "        if p == 0.0 or n == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.tp+self.tn)/(p+n)\n",
    "    \n",
    "    def error_rate(self):\n",
    "        p = self.get_p()\n",
    "        n = self.get_n()\n",
    "        if p == 0.0 or n == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.fp+self.fn)/(p+n)\n",
    "    \n",
    "    def recall(self):\n",
    "        p = self.get_p()\n",
    "        if p == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.tp)/(p)\n",
    "    \n",
    "    def specificity(self):\n",
    "        n = self.get_n()\n",
    "        if n == 0.0:\n",
    "            return 0.0\n",
    "        return float(self.tn)/(n)\n",
    "    \n",
    "    def percision(self):\n",
    "        divider = self.tp + self.fp\n",
    "        if(divider == 0.0):\n",
    "            return 0.0\n",
    "        return float(self.tp)/(divider)\n",
    "    \n",
    "    def f1(self):\n",
    "        percision = self.percision()\n",
    "        recall = self.recall()\n",
    "        total = percision + recall\n",
    "        if(total == 0.0):\n",
    "            return 0.0\n",
    "        return float(2*percision*recall)/(percision+recall)\n",
    "    \n",
    "    def weighted_f1(self):\n",
    "        return float(self.f1()) * self.support\n",
    "    \n",
    "    def weighted_recall(self):\n",
    "        return float(self.recall()) * self.support\n",
    "    \n",
    "    def weighted_percision(self):\n",
    "        return float(self.percision()) * self.support\n",
    "    \n",
    "    def weighted_error(self):\n",
    "        return float(self.error_rate()) * self.support \n",
    "    \n",
    "    def display_report(self,name):\n",
    "#         print('%5s %5s %5s %5s %5s' % ('Name','Accuracy','Percision','Recall','F1'))\n",
    "        print('%7s'% name,end =' ')\n",
    "        print('%7.2f' % self.accuracy(),end=' ')\n",
    "        print('%7.2f' %self.percision(),end=' ')\n",
    "        print('%7.2f' %self.recall(),end=' ')\n",
    "        print('%7.2f' %self.f1(),end=' ')\n",
    "        print('%7d' %self.support)\n",
    "    def display_matrix(self):\n",
    "        print(f'TP = {self.tp} FP = {self.fp}')\n",
    "        print(f'FN = {self.fn} TP = {self.tn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "associate-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def create_cm_list(self,actualList,predictList,labels):\n",
    "        cm_list = {}\n",
    "        for label in labels:\n",
    "            TP = 0\n",
    "            FN = 0\n",
    "            FP = 0\n",
    "            TN = 0\n",
    "            mask = np.isin(actualList,label)\n",
    "            support = mask.sum()\n",
    "            for index,predict in enumerate(predictionList):\n",
    "                actual = actualList[index]\n",
    "                if(predict == label == actual):\n",
    "                    TP +=1\n",
    "                elif(predict == actual and predict != label):\n",
    "                    TN +=1\n",
    "                elif(predict != actual and predict == label):\n",
    "        #             FN +=1\n",
    "                    FP += 1\n",
    "                elif(predict != actual and actual != label):\n",
    "                    TN +=1\n",
    "                elif(predict != actual and actual == label):\n",
    "        #             FP +=1\n",
    "                    FN+=1\n",
    "            cm = ConfussionMatrix(TP,FP,FN,TN,support,label)\n",
    "            cm_list[label] = cm\n",
    "        return cm_list\n",
    "\n",
    "    def create_report(self,cm_list):\n",
    "        totalTP =0\n",
    "        totalFP =0\n",
    "        totalFN =0\n",
    "        totalSupport =0\n",
    "        totalF1 =0\n",
    "        totalRecall =0\n",
    "        totalPercision =0\n",
    "        totalWeightedRecall =0\n",
    "        totalWeightedPercision =0\n",
    "        totalWeightedF1=0\n",
    "        totalError=0\n",
    "        totalWeightedError=0\n",
    "        for label in labels:\n",
    "            cm = cm_list[label]\n",
    "            totalTP += cm.tp\n",
    "            totalFP += cm.fp\n",
    "            totalFN += cm.fn\n",
    "            totalF1 += cm.f1()\n",
    "            totalWeightedF1 += cm.weighted_f1()\n",
    "            totalSupport += cm.support\n",
    "            totalRecall += cm.recall()\n",
    "            totalPercision += cm.percision()\n",
    "            totalWeightedRecall += cm.weighted_recall()\n",
    "            totalWeightedPercision += cm.weighted_percision()\n",
    "            totalError += cm.error_rate()\n",
    "            totalWeightedError += cm.weighted_error()\n",
    "            print('-----------------------------')\n",
    "            print(f'Label:{cm.label}')\n",
    "            print(f'Accuracy: {cm.accuracy():.2f}')\n",
    "            print(f'Error: {cm.error_rate():.2f}')\n",
    "            print(f'Specificity: {cm.specificity():.2f}')\n",
    "            print(f'Percision: {cm.percision():.2f}')\n",
    "            print(f'Recall: {cm.recall():.2f}')\n",
    "            print(f'F1-score: {cm.f1():.2f}')\n",
    "            print(f'support: {cm.support:d}')\n",
    "            cm.display_matrix()\n",
    "            \n",
    "        print('-----------------------------')\n",
    "        nol = len(labels)\n",
    "        P = totalTP+totalFN\n",
    "        micro_f1 = totalTP/P\n",
    "        macro_f1 = (totalF1)/nol\n",
    "        weigthed_f1 = totalWeightedF1 / totalSupport\n",
    "        if(nol > 2):\n",
    "            print(f'Micro f1/Accuracy: {micro_f1:.2f}')\n",
    "        print(f'Macro f1: {macro_f1:.2f}')\n",
    "        print(f'Weighted f1: {weigthed_f1:.2f}')\n",
    "        \n",
    "        micro_error = (totalFP+totalFN)/totalSupport\n",
    "        macro_error = (totalError)/nol\n",
    "        weigthed_error = totalWeightedError / totalSupport\n",
    "        if(nol > 2):\n",
    "            print(f'Micro error: {micro_error:.2f}')\n",
    "        print(f'Macro error: {macro_error:.2f}')\n",
    "        print(f'Weighted error: {weigthed_error:.2f}')     \n",
    "        \n",
    "        micro_percision = (totalTP)/(totalTP+totalFP)\n",
    "        macro_percision = totalPercision / nol\n",
    "        weighted_percision = totalWeightedPercision / totalSupport\n",
    "        if(nol > 2):\n",
    "            print(f'Micro percision: {micro_percision:.2f}')\n",
    "        print(f'Macro percision: {macro_percision:.2f}')\n",
    "        print(f'Weighted percision: {weighted_percision:.2f}')\n",
    "\n",
    "        micro_recall = totalTP/P\n",
    "        macro_recall = totalRecall / nol\n",
    "        weighted_recall = totalWeightedRecall / totalSupport\n",
    "        if(nol > 2):\n",
    "            print(f'Micro recall: {micro_recall:.2f}')\n",
    "        print(f'Macro recall: {macro_recall:.2f}')\n",
    "        print(f'Weighted recall: {weighted_recall:.2f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "approximate-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Label:no_recurrence_events\n",
      "Accuracy: 0.62\n",
      "Error: 0.38\n",
      "Specificity: 0.40\n",
      "Percision: 0.67\n",
      "Recall: 0.75\n",
      "F1-score: 0.71\n",
      "support: 8\n",
      "TP = 6 FP = 3\n",
      "FN = 2 TP = 2\n",
      "-----------------------------\n",
      "Label:recurrence_events\n",
      "Accuracy: 0.62\n",
      "Error: 0.38\n",
      "Specificity: 0.75\n",
      "Percision: 0.50\n",
      "Recall: 0.40\n",
      "F1-score: 0.44\n",
      "support: 5\n",
      "TP = 2 FP = 2\n",
      "FN = 3 TP = 6\n",
      "-----------------------------\n",
      "Macro f1: 0.58\n",
      "Weighted f1: 0.61\n",
      "Macro error: 0.38\n",
      "Weighted error: 0.38\n",
      "Macro percision: 0.58\n",
      "Weighted percision: 0.60\n",
      "Macro recall: 0.57\n",
      "Weighted recall: 0.62\n"
     ]
    }
   ],
   "source": [
    "report = Report()\n",
    "newList = report.create_cm_list(actualList,predictionList,labels)\n",
    "report.create_report(newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "welsh-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list = {}\n",
    "for label in labels:\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    mask = np.isin(actualList,label)\n",
    "    support = mask.sum()\n",
    "    for index,predict in enumerate(predictionList):\n",
    "        actual = actualList[index]\n",
    "        if(predict == label == actual):\n",
    "            TP +=1\n",
    "        elif(predict == actual and predict != label):\n",
    "            TN +=1\n",
    "        elif(predict != actual and predict == label):\n",
    "#             FN +=1\n",
    "            FP += 1\n",
    "        elif(predict != actual and actual != label):\n",
    "            TN +=1\n",
    "        elif(predict != actual and actual == label):\n",
    "#             FP +=1\n",
    "            FN+=1\n",
    "    cm = ConfussionMatrix(TP,FP,FN,TN,support)\n",
    "    cm_list[label] = cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "neither-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1/Accuracy: 0.28\n",
      "Macro percision: 0.26\n",
      "Weighted percision: 0.26\n",
      "Macro recall: 0.29\n",
      "Weighted recall: 0.28\n",
      "Macro f1: 0.24\n",
      "Weighted f1: 0.24\n"
     ]
    }
   ],
   "source": [
    "totalTP =0\n",
    "totalFP =0\n",
    "totalFN =0\n",
    "totalSupport =0\n",
    "totalF1 =0\n",
    "totalRecall =0\n",
    "totalPercision =0\n",
    "totalWeightedRecall =0\n",
    "totalWeightedPercision =0\n",
    "totalWeightedF1=0\n",
    "for label in labels:\n",
    "    cm = cm_list[label]\n",
    "    totalTP += cm.tp\n",
    "    totalFP += cm.fp\n",
    "    totalFN += cm.fn\n",
    "    totalF1 += cm.f1()\n",
    "    totalWeightedF1 += cm.weighted_f1()\n",
    "    totalSupport += cm.support\n",
    "    totalRecall += cm.recall()\n",
    "    totalPercision += cm.percision()\n",
    "    totalWeightedRecall += cm.weighted_recall()\n",
    "    totalWeightedPercision += cm.weighted_percision()\n",
    "nol = len(labels)    \n",
    "micro_f1 = totalTP/(totalTP+totalFN)\n",
    "print(f'Micro f1/Accuracy: {micro_f1:.2f}')\n",
    "\n",
    "macro_percision = totalPercision / nol\n",
    "weighted_percision = totalWeightedPercision / totalSupport\n",
    "print(f'Macro percision: {macro_percision:.2f}')\n",
    "print(f'Weighted percision: {weighted_percision:.2f}')\n",
    "\n",
    "macro_recall = totalRecall / nol\n",
    "weighted_recall = totalWeightedRecall / totalSupport\n",
    "print(f'Macro recall: {macro_recall:.2f}')\n",
    "print(f'Weighted recall: {weighted_recall:.2f}')\n",
    "\n",
    "macro_f1 = (totalF1)/nol\n",
    "weigthed_f1 = totalWeightedF1 / totalSupport\n",
    "print(f'Macro f1: {macro_f1:.2f}')\n",
    "print(f'Weighted f1: {macro_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "label = labels[1]\n",
    "print(label)\n",
    "mask = np.isin(predictionList,label)\n",
    "idxs = np.where(mask)\n",
    "for index in idxs[0]:\n",
    "    predict = predictionsList[index]\n",
    "    actual = actualList[index]\n",
    "    print(f'Acutal {actual} But {predict}')\n",
    "    if(predict == actual):\n",
    "        TP += 1\n",
    "    elif(predict == actual != label):\n",
    "        TN += 1\n",
    "print(f'{TP} {FP}')\n",
    "print(f'{FN} {TN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = C45()\n",
    "model.read_csv('audiology_standardized_train.txt')\n",
    "model.remove_feature(model.df.columns[0])\n",
    "# model.identify_feature()\n",
    "model.info()\n",
    "print('============================================')\n",
    "model.create_tree()\n",
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value(currentNode,data):\n",
    "    found = False\n",
    "    if currentNode.type == model.LABEL:\n",
    "        return currentNode\n",
    "    for child in currentNode.children:\n",
    "#         print(f'Data:{str(data[currentNode.name])} type({type(str(data[currentNode.name]))}) compare child {str(child.name)} type({type(str(child.name))})')\n",
    "        if(str(data[currentNode.name]) == str(child.name)):\n",
    "            found = True\n",
    "            return child\n",
    "    if not found:\n",
    "        return currentNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(data):\n",
    "    #initialize with root of tree\n",
    "    currentNode = model.tree\n",
    "    #start to find prediction\n",
    "    while True:\n",
    "#         print(currentNode.name,currentNode.type)\n",
    "#         if it is label mean leaf\n",
    "        if currentNode.type == model.LABEL:\n",
    "            return currentNode.name\n",
    "        #keep decending\n",
    "        valueNode = check_value(currentNode,data)\n",
    "        if(currentNode == valueNode):\n",
    "            return missing_get_label(currentNode)\n",
    "        # if it is leaf return result\n",
    "#         if valueNode.type == model.LABEL:\n",
    "#             return valueNode.name\n",
    "        #go to next node\n",
    "        currentNode = valueNode.children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_get_label(currentNode):\n",
    "    labels = []\n",
    "    for node in LevelOrderIter(currentNode):\n",
    "#         print(node.name,node.type)\n",
    "        if(node.type == model.LABEL):\n",
    "            labels.append(node.name)\n",
    "    labels = np.array(labels)\n",
    "    unique_label = np.unique(labels)\n",
    "    label_list = {}\n",
    "#     print(labels)\n",
    "#     print(unique_label)\n",
    "    for item in unique_label:\n",
    "        mask = np.isin(labels,item)\n",
    "        idxs = np.where(mask)\n",
    "        label_list[item] = len(idxs)\n",
    "#         print(item,len(idxs))\n",
    "    bestLabel = missing_best_label(label_list)\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_best_label(label_list):\n",
    "    key_list = list(label_list)\n",
    "#     print(key_list)\n",
    "    bestLabel = label_list[key_list[0]]\n",
    "    bestCount = 0\n",
    "    for key in key_list:\n",
    "        labelCount = label_list[key]\n",
    "        if(labelCount > bestCount):\n",
    "            bestCount = labelCount\n",
    "#             print(key,bestCount)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name,number_of_entries,dataset,features = model.read_testset('golf_test.txt')\n",
    "predictions = []\n",
    "# print(f'Number of entries: {number_of_entries}')\n",
    "# print(f'Label: {label_name}')\n",
    "# print(f'Features: {features}')\n",
    "data = dataset.loc[2]\n",
    "# print(data)\n",
    "label = get_label(data)\n",
    "print(label)\n",
    "# for index in dataset.index:\n",
    "#     data = dataset.loc[index]\n",
    "#     label = model.get_label(data)\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for node in LevelOrderIter(label):\n",
    "    print(node.name,node.type)\n",
    "    if(node.type == model.LABEL):\n",
    "        labels.append(node.name)\n",
    "labels = np.array(labels)\n",
    "unique_label = np.unique(labels)\n",
    "label_list = {}\n",
    "print(labels)\n",
    "print(unique_label)\n",
    "for item in unique_label:\n",
    "    mask = np.isin(labels,item)\n",
    "    idxs = np.where(mask)\n",
    "    label_list[item] = len(idxs)\n",
    "    print(item,len(idxs))\n",
    "bestLabel = missing_best_label(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = list(label_list)\n",
    "print(key_list)\n",
    "bestLabel = label_list[key_list[0]]\n",
    "bestCount = 0\n",
    "for key in key_list:\n",
    "    labelCount = label_list[key]\n",
    "    if(labelCount > bestCount):\n",
    "        bestCount = labelCount\n",
    "        print(key,bestCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name,number_of_entries,dataset,features = model.read_testset('golf_test.txt')\n",
    "predictions = []\n",
    "# print(f'Number of entries: {number_of_entries}')\n",
    "# print(f'Label: {label_name}')\n",
    "# print(f'Features: {features}')\n",
    "data = dataset.loc[2]\n",
    "# print(data)\n",
    "label = get_label(data)\n",
    "print(label)\n",
    "# for index in dataset.index:\n",
    "#     data = dataset.loc[index]\n",
    "#     label = model.get_label(data)\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[dataset.columns[0]].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,dataset = model.predict_file('golf_test.txt')\n",
    "model.display_predictions(predictions,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = C45()\n",
    "model.read_csv('golf_train.txt')\n",
    "model.remove_feature('RID')\n",
    "# model.identify_feature()\n",
    "model.info()\n",
    "print('============================================')\n",
    "model.create_tree()\n",
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,dataset = model.predict_file('student_test.txt')\n",
    "model.display_predictions(predictions,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,dataset = model.predict_file('student_test.txt')\n",
    "for index in dataset.index:\n",
    "    print(dataset[dataset.columns[0]][index],dataset[model.label_name][index],predictions[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.display_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testset(file):\n",
    "    df = pd.read_table(file, sep=';', engine='python')\n",
    "    label_name = df.columns[-1]\n",
    "    number_of_entries = len(df)\n",
    "    features = [item for item in df.columns if item != label_name]\n",
    "    return label_name,number_of_entries,df,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value(currentNode,data):\n",
    "    if currentNode.type == model.LABEL:\n",
    "        return currentNode\n",
    "    for child in currentNode.children:\n",
    "#         print(f'Data:{str(data[currentNode.name])} type({type(str(data[currentNode.name]))}) compare child {str(child.name)} type({type(str(child.name))})')\n",
    "        if(str(data[currentNode.name]) == str(child.name)):\n",
    "            found = True\n",
    "            return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(data):\n",
    "    #initialize with root of tree\n",
    "    currentNode = model.tree\n",
    "    #start to find prediction\n",
    "    while True:\n",
    "#         print(currentNode.name,currentNode.type)\n",
    "#         if it is label mean leaf\n",
    "        if currentNode.type == model.LABEL:\n",
    "            return currentNode.name\n",
    "        #keep decending\n",
    "        valueNode = check_value(currentNode,data)\n",
    "        # if it is leaf return result\n",
    "#         if valueNode.type == model.LABEL:\n",
    "#             return valueNode.name\n",
    "        #go to next node\n",
    "        currentNode = valueNode.children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(file):\n",
    "    label_name,number_of_entries,dataset,features = read_testset(file)\n",
    "    predictions = []\n",
    "    print(f'Number of entries: {number_of_entries}')\n",
    "    print(f'Label: {label_name}')\n",
    "    print(f'Features: {features}')\n",
    "    for index in dataset.index:\n",
    "        data = dataset.loc[index]\n",
    "        try:\n",
    "            label = get_label(data)\n",
    "        except:\n",
    "            label = 'No label'\n",
    "        predictions.append(label)\n",
    "        print(f'Index: {index}')\n",
    "        print(f'Actual: {data[model.label_name]}')\n",
    "        print(f'Predicted: {label}')\n",
    "    return predictions,dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,dataset=predict_file('breast_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# currentNode = root\n",
    "# root = model.tree\n",
    "# found = False;\n",
    "# for index in dataset.index:\n",
    "#         data = dataset[currentNode.name][index]\n",
    "#         found = False\n",
    "#         for child in currentNode.children:\n",
    "#             if (data == child.name):\n",
    "#                 currentNode = child\n",
    "#                 found = True\n",
    "#                 break\n",
    "#         if found:\n",
    "#             currentNode = child\n",
    "#         print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature(feature_list):\n",
    "    bestGain = 0.0\n",
    "    for key in feature_list: \n",
    "        featureObj = feature_list[key]\n",
    "        if featureObj.gain_ratio > bestGain:\n",
    "            bestFeature = featureObj\n",
    "            bestGain = featureObj.gain_ratio\n",
    "    if bestGain == 0.0:\n",
    "        return -99\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_features(feature_list,df):\n",
    "    labelObj = feature_list[model.label_name]\n",
    "    for key in feature_list:\n",
    "        featureObj = feature_list[key]\n",
    "        featureObj.info = model.calc_info(featureObj,labelObj,df)\n",
    "        featureObj.split_info = model.calc_info(featureObj,featureObj,df)\n",
    "    labelObj = feature_list[model.label_name]\n",
    "    for key in feature_list:\n",
    "        featureObj = feature_list[key]\n",
    "        if featureObj == labelObj:\n",
    "            continue\n",
    "        featureObj.gain = labelObj.info - featureObj.info\n",
    "        featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "        print(featureObj.name,featureObj.info,featureObj.gain,featureObj.split_info,featureObj.gain_ratio)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'root'\n",
    "LABEL = 'label'\n",
    "DECISION = 'class'\n",
    "VALUE = 'value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feature(dataset):\n",
    "    feature_list = {}\n",
    "    for col in dataset:\n",
    "        if col not in model.except_features:\n",
    "            feature = Feature(name=col,unique=dataset[col].unique())\n",
    "            feature_list[col] = feature\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_label(labelObj,df):\n",
    "    count = 0\n",
    "    bestLabel = labelObj.unique[0]\n",
    "    for value in labelObj.unique:\n",
    "        idxs = df[(df[labelObj.name]==value)].index\n",
    "        newCount = len(idxs)\n",
    "        if newCount > count:\n",
    "            bestLabel = value\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(name,value,dataset):\n",
    "    dataset = dataset.loc[(dataset[name]==value)]\n",
    "    dataset = dataset.drop(name,axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_value_node(feature,df,currentNode):\n",
    "    for value in feature.unique:\n",
    "        dataset = split_dataset(feature.name,value,df)\n",
    "        newNode = Node(value,parent=currentNode,dataset=dataset,type=VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre,_,node in RenderTree(root,DoubleStyle):\n",
    "        print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = model.feature_list\n",
    "feature_list = find_feature(model.df)\n",
    "feature_list = find_best_features(feature_list,model.df)\n",
    "bestFeature = best_feature(feature_list)\n",
    "root = Node(bestFeature.name,type=ROOT)\n",
    "for value in bestFeature.unique:\n",
    "    dataset = split_dataset(bestFeature.name,value,model.df)\n",
    "#     dataset = model.df.loc[(model.df[bestFeature.name]==value)]\n",
    "#     dataset = dataset.drop(bestFeature.name,axis=1)\n",
    "    newNode = Node(value,parent=root,dataset=dataset,type=VALUE)\n",
    "for node in LevelOrderIter(root):\n",
    "    print(f'Node: {node.name} Type:{node.type}')\n",
    "    if node != root and node.type != LABEL and node.type != DECISION:\n",
    "#         print(f'Node: {node.name}')\n",
    "        print(node.dataset,node.type)\n",
    "        feature_list = find_feature(node.dataset)\n",
    "        print(f'Length: {len(feature_list)}')\n",
    "        feature_list = find_best_features(feature_list,node.dataset)\n",
    "        bestFeature = best_feature(feature_list)\n",
    "        if(bestFeature != -99):\n",
    "            print(f\"Best feature: {bestFeature.name}\")\n",
    "            newNode = Node(bestFeature.name,parent=node,type=DECISION)\n",
    "            create_value_node(bestFeature,node.dataset,newNode)\n",
    "        else:\n",
    "            labelObj = feature_list[model.label_name]\n",
    "            best_label = find_best_label(labelObj,node.dataset)\n",
    "            print(f'Selected label: {best_label}')\n",
    "            newNode = Node(best_label,parent=node,type=LABEL)\n",
    "    print('=================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "## developed for find_best_featrues method\n",
    "# feature_list = model.feature_list\n",
    "# labelObj = feature_list[model.label_name]\n",
    "# selected_features = []\n",
    "# for key in feature_list:\n",
    "#     featureObj = feature_list[key]\n",
    "#     featureObj.info = model.calc_info(featureObj,labelObj,model.df)\n",
    "#     featureObj.split_info = model.calc_info(featureObj,featureObj,model.df)\n",
    "# labelObj = feature_list[model.label_name]\n",
    "# for key in feature_list:\n",
    "#     featureObj = feature_list[key]\n",
    "#     if featureObj == labelObj:\n",
    "#         continue\n",
    "#     featureObj.gain = labelObj.info - featureObj.info\n",
    "#     featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "#     print(featureObj.name,featureObj.info,featureObj.gain,featureObj.split_info,featureObj.gain_ratio)\n",
    "# bestFeature = best_feature(feature_list)\n",
    "# selected_features.append(bestFeature)\n",
    "# print('Best feature:',bestFeature.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "## old find best features method\n",
    "# def find_best_features(feature_list,labelObj,df):\n",
    "#     for key in feature_list:\n",
    "#         featureObj = feature_list[key]\n",
    "#         featureObj.info = model.calc_info(featureObj,labelObj,df)\n",
    "#         featureObj.split_info = model.calc_info(featureObj,featureObj,df)\n",
    "#     for key in feature_list:\n",
    "#         featureObj = feature_list[key]\n",
    "#         if featureObj == labelObj:\n",
    "#             continue\n",
    "#         featureObj.gain = labelObj.info - featureObj.info\n",
    "#         featureObj.gain_ratio = featureObj.gain / featureObj.split_info\n",
    "#         print(featureObj.name,featureObj.info,featureObj.gain,featureObj.split_info,featureObj.gain_ratio)\n",
    "#     bestFeature = best_feature(feature_list)\n",
    "#     return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = model.feature_list\n",
    "# feature_list = find_best_features(feature_list,model.df)\n",
    "# bestFeature = best_feature(feature_list)\n",
    "# print('Best feature:',bestFeature.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre,_,node in RenderTree(root,DoubleStyle):\n",
    "    try:\n",
    "        print(\"%s%s\\n%s\" % (pre, node.name,node.dataset))\n",
    "    except:\n",
    "        print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in bestFeature.unique:\n",
    "    print(value)\n",
    "    dataset = model.df.loc[(model.df[bestFeature.name]==value)]\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestFeature.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in feature_list:\n",
    "    print(feature_list[key].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.df\n",
    "number_of_entries = len(df)\n",
    "info = 0.0\n",
    "for label_value in labelObj.unique:\n",
    "    idxs = df[(df[labelObj.name]==label_value)].index\n",
    "    occur = len(idxs)\n",
    "    print('occur:',occur)\n",
    "    valueP = float(occur)/number_of_entries\n",
    "    info = info - (valueP * ( log2(valueP) ) )\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.log(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info(featureObj,labelObj):\n",
    "#     featureObj = model.feature_list['age']\n",
    "#     labelObj = model.feature_list['buys_computer']\n",
    "    print(f'Processing {featureObj.name}')\n",
    "    df = model.df\n",
    "    sum_info = 0.0\n",
    "    classP = 0.0\n",
    "    for feature_value in featureObj.unique:\n",
    "        info = 0.0\n",
    "        idxs = df[(df[featureObj.name]==feature_value)].index\n",
    "        Dj = len(idxs)\n",
    "        print(f'Occurance: {Dj}, ClassP: {classP}')\n",
    "        classP = float(Dj)/model.number_of_entries\n",
    "    #     print(f'{Dj}/{model.number_of_entries}')\n",
    "        for label_value in labelObj.unique:\n",
    "            idxs = df[(df[featureObj.name]==feature_value) & (df[labelObj.name]==label_value)].index\n",
    "            occur = len(idxs)\n",
    "            print(f'{feature_value} {label_value} {occur}/{Dj}')\n",
    "            valueP = float(occur)/Dj\n",
    "            info = info - (valueP * ( log2(valueP) ) )\n",
    "        split_info = classP * info\n",
    "        sum_info = sum_info + split_info\n",
    "    print(f'Info {featureObj.name}(D) = {sum_info}')\n",
    "    print('========================================================')\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelObj = feature_list[model.label_name]\n",
    "for key in feature_list:\n",
    "    featureObj = feature_list[key]\n",
    "    featureObj.info = model.calc_info(featureObj,labelObj,model.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureObj = model.feature_list['age']\n",
    "labelObj = model.feature_list['buys_computer']\n",
    "print(f'Processing {featureObj.name}')\n",
    "sum_info = 0.0\n",
    "for feature_value in featureObj.unique:\n",
    "    info = 0.0\n",
    "    idxs = df[(df[feature_obj.name]==feature_value)].index\n",
    "    Dj = len(idxs)\n",
    "    print(f'Occurance: {Dj}, ClassP: {classP}')\n",
    "    classP = float(Dj)/model.number_of_entries\n",
    "#     print(f'{Dj}/{model.number_of_entries}')\n",
    "    for label_value in labelObj.unique:\n",
    "        idxs = df[(df[feature_obj.name]==feature_value) & (df[label_name]==label_value)].index\n",
    "        occur = len(idxs)\n",
    "        valueP = float(occur)/Dj\n",
    "        info = info - (valueP * ( log2(valueP) ) )\n",
    "        print(feature_value,label_value,occur)\n",
    "    split_info = classP * info\n",
    "    sum_info = sum_info + split_info\n",
    "print(f'Info {featureObj.name}(D) = {sum_info}')\n",
    "print('========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.df\n",
    "feature_list = model.feature_list\n",
    "for key in feature_list:\n",
    "    print(key)\n",
    "    subdf = df[[key,label_name]]\n",
    "    feature_list[key].dataset = subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "feaVec=[]\n",
    "feature_list = model.feature_list\n",
    "label_name = model.label_name\n",
    "df = model.df\n",
    "for key in feature_list:\n",
    "    if key != label_name:\n",
    "        print(f'---{key}---')\n",
    "        feature_obj = feature_list[key]\n",
    "        for feature_value in feature_obj.unique:\n",
    "                print(feature_value)\n",
    "#                 idxs = df[(df[feature_obj.name]==feature_value) & (df[label_name]==label_value)].index\n",
    "#                 subdf = df.loc[(df[feature_obj.name]==feature_value) & (df[label_name]==label_value)]\n",
    "                subdf = df[[feature_obj.name,label_name]]\n",
    "                print(subdf)\n",
    "#                 count = len(dataset)\n",
    "#                 probability = float(count/model.number_of_entries)\n",
    "#                 print(feature_value,label_value,probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-authority",
   "metadata": {},
   "source": [
    "Developed for read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "except_features = []\n",
    "df = pd.read_table('student_train.txt', sep=';', engine='python')\n",
    "label_name = df.columns[-1]\n",
    "except_features.append('RID')\n",
    "number_of_entries = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(except_features)\n",
    "print(number_of_features,label_name)\n",
    "print(df.columns)\n",
    "print(number_of_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-greenhouse",
   "metadata": {},
   "source": [
    "Identify Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list={}\n",
    "for col in df:\n",
    "    if col not in except_features:\n",
    "        feature = Feature(name=col,unique=df[col].unique())\n",
    "        feature_list[col] = feature\n",
    "#     feature_list[col] = df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in feature_list:\n",
    "    print(feature_list[key].unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-focus",
   "metadata": {},
   "source": [
    "Develop feature vector to count the gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "feaVec=[]\n",
    "for key in feature_list:\n",
    "    if key != label_name:\n",
    "        feature_obj = feature_list[key]\n",
    "        for feature_value in feature_obj.unique:\n",
    "            for label_value in feature_list[label_name].unique:\n",
    "                print(feature_value,label_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-kidney",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2019/07/how-to-filter-pandas-dataframe.html\n",
    "\n",
    "solution\n",
    "https://discuss.analyticsvidhya.com/t/how-to-resolve-python-error-cannot-compare-a-dtyped-int64-array-with-a-scalar-of-type-bool/73065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_obj = feature_list['age']\n",
    "df[(df[feature_obj.name]==\"youth\") & (df[label_name]=='no')].index\n",
    "## use to split data\n",
    "# df.loc[(df[feature_obj.name]==\"youth\") & (df[label_name]=='no')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
